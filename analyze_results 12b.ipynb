{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8ad521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import joblib\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.legend_handler import HandlerBase\n",
    "import seaborn as sns\n",
    "\n",
    "from nilearn import plotting \n",
    "from nilearn.image import smooth_img, swap_img_hemispheres\n",
    "\n",
    "from nilearn.input_data import NiftiMasker\n",
    "import nibabel as nib\n",
    "\n",
    "import scipy.stats\n",
    "from scipy.stats import pearsonr, spearmanr, ttest_ind\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import llms_brain_lateralization as lbl\n",
    "from llms_brain_lateralization import make_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3a8096-033a-4b0f-8628-5d8fbe69b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc={'font.size': 12, 'axes.labelsize': 14, \n",
    "    'xtick.labelsize': 12, 'ytick.labelsize': 12}\n",
    "sns.set(rc=rc)\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef525dc-cf61-47d2-b2ef-4820e773c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bf6fe2-67af-460c-ad5c-f43dec793897",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_fig:\n",
    "    fig_folder = lbl.figures_folder\n",
    "    make_dir(fig_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3591d5d1-53f2-4d23-bdab-76cfb9e645e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nifti_masker = NiftiMasker(mask_img='mask_lpp_en.nii.gz')\n",
    "nifti_masker.fit()\n",
    "\n",
    "n_voxels = nifti_masker.n_elements_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36d7918-b888-40af-9f43-ef64a6b24449",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_folder = lbl.llms_brain_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832f9b1b-c18d-466e-9b1c-ddd0acad2684",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [0, 1, 8, 16, 64, 128, 256, 512, 1000, 3000, 13000, 23000, 33000, 43000, 53000, 63000, 73000, 83000, 93000, 103000, 113000, 123000, 133000, 143000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e2352a-d432-49ee-b168-a08543a0156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"EleutherAI/pythia-12b-deduped-step:\" + str(step) for step in steps]\n",
    "n_layers = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8094fc5-ce52-484c-aa8b-7c9f1795d28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_models = len(model_names)\n",
    "print(n_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ff6672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afef968-bca0-42f8-9517-68204f437933",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_layers_voxels_models = []\n",
    "for model_name in model_names:\n",
    "    corr_layers_voxels = []\n",
    "    for idx_layer in range(32):\n",
    "        filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, idx_layer))\n",
    "        with open(filename, 'rb') as f:\n",
    "            corr_voxels = joblib.load(f)\n",
    "        corr_layers_voxels.append(corr_voxels)\n",
    "        print(corr_layers_voxels)\n",
    "    corr_layers_voxels_models.append(np.array(corr_layers_voxels))\n",
    "print(corr_layers_voxels_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71917c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr_layers_voxels_models)\n",
    "color_models = list(sns.color_palette('plasma', n_colors=len(corr_layers_voxels_models)))\n",
    "print(len(corr_layers_voxels_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1efbdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "arr2 = []\n",
    "for corr_layers_voxels in corr_layers_voxels_models:\n",
    "    arr.append(np.mean(np.argmax(corr_layers_voxels, axis=0)))\n",
    "    arr2.append(np.var(np.argmax(corr_layers_voxels, axis=0)) / 10)\n",
    "plt.plot(steps, arr)\n",
    "plt.plot(steps, arr2)\n",
    "plt.title(\"argmax moyen en bleu, variance normalisée en rouge\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e01fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ ROIs analysis ################################\n",
    "\n",
    "roi_names = ['TP', 'aSTS', 'pSTS', 'AG_TPJ', 'BA44', 'BA45', 'BA47']\n",
    "n_rois = len(roi_names)\n",
    "folder_mask = 'roi_masks'\n",
    "\n",
    "roi_list = [os.path.join(folder_mask, '{}.nii.gz'.format(roi_name)) for roi_name in roi_names]\n",
    "roi_list_r = [swap_img_hemispheres(roi_mask) for roi_mask in roi_list]\n",
    "rois_t = nifti_masker.transform(roi_list + roi_list_r)\n",
    "idx_rois = [np.flatnonzero(roi_t == 1.0) for roi_t in rois_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf3f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "np.random.seed(0)\n",
    "data = [np.argmax(corr_layers_voxels, axis=0) for corr_layers_voxels in corr_layers_voxels_models]\n",
    "\n",
    "\n",
    "arr = np.zeros(n_voxels)\n",
    "arr = arr * 0\n",
    "arr[np.where(np.abs(data[-1]-8) <= 1)] = 1\n",
    "\n",
    "imgtmp = nifti_masker.inverse_transform(arr)\n",
    "\n",
    "temp_filename = f'temppp_{0}.png'\n",
    "plotting.plot_img_on_surf(imgtmp,\n",
    "                        surf_mesh='fsaverage5',\n",
    "                        views=['lateral'],\n",
    "                        hemispheres=['left', 'right'],\n",
    "                        cmap='Spectral_r',\n",
    "                        vmax=1,\n",
    "                        symmetric_cbar=False,\n",
    "                        cbar_tick_format='%.2f',\n",
    "                        colorbar=True,\n",
    "                        title=\"Cluster layer 7, 8, 9, 12b\")\n",
    "plt.show()\n",
    "\n",
    "arr = arr * 0\n",
    "arr[np.where(np.abs(data[-1]-8) <= 1)] = 1\n",
    "arr[idx_rois[1]] = 2\n",
    "\n",
    "imgtmp = nifti_masker.inverse_transform(arr)\n",
    "\n",
    "temp_filename = f'temppp_{0}.png'\n",
    "plotting.plot_img_on_surf(imgtmp,\n",
    "                        surf_mesh='fsaverage5',\n",
    "                        views=['lateral'],\n",
    "                        hemispheres=['left', 'right'],\n",
    "                        cmap='Spectral_r',\n",
    "                        vmax=2,\n",
    "                        symmetric_cbar=False,\n",
    "                        cbar_tick_format='%.2f',\n",
    "                        colorbar=True,\n",
    "                        title=\"aires a grand offset\")\n",
    "plt.show()\n",
    "\n",
    "# Création des traces pour chaque distribution\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, dist in enumerate(data):\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=dist,\n",
    "            name=f'Time {i}',\n",
    "            visible=False,  # Masquer toutes les traces sauf la première\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Rendre la première trace visible\n",
    "fig.data[0].visible = True\n",
    "\n",
    "# Création des boutons pour le slider\n",
    "gsteps = []\n",
    "for i in range(len(data)):\n",
    "    gstep = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(data)},\n",
    "              {\"title\": f\"Distribution at Time {steps[i]}\"}],\n",
    "    )\n",
    "    gstep[\"args\"][0][\"visible\"][i] = True  # Rendre la trace actuelle visible\n",
    "    gsteps.append(gstep)\n",
    "\n",
    "sliders = [dict(\n",
    "    active=0,\n",
    "    currentvalue={\"prefix\": \"Time: \"},\n",
    "    pad={\"t\": 50},\n",
    "    steps=gsteps\n",
    ")]\n",
    "\n",
    "fig.update_layout(\n",
    "    sliders=sliders,\n",
    "    title=\"Evolution of Distribution Over Time\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d65f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh = np.where(np.abs(data[-1]-8) <= 1)\n",
    "arr = np.array(corr_layers_voxels_models[-1])\n",
    "print(arr.shape)\n",
    "arr = arr[:, np.where(np.abs(data[-1]-8) <= 1)[0]]\n",
    "print(arr.shape)\n",
    "arr = np.mean(arr, axis=1)\n",
    "print(arr.shape)\n",
    "plt.plot(arr)\n",
    "plt.title(\"corrélation par layer des zones des cortex auditifs et autres voxels du cluster 8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b3173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(corr_layers_voxels_models[-1])\n",
    "print(arr.shape)\n",
    "arr = arr * 0\n",
    "wh = np.where(np.abs(data[-1]-8) <= 1)\n",
    "arr[:, wh] = 1\n",
    "imgtmp = nifti_masker.inverse_transform(arr[0])\n",
    "display = plotting.plot_glass_brain(imgtmp, threshold=0., display_mode='lyrz', \n",
    "                          vmin=0., cmap='Spectral_r', \n",
    "                          plot_abs=True, colorbar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812bf866",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh = np.where(np.abs(data[-1]-8) <= 1)\n",
    "arr = np.array(corr_layers_voxels_models[-1])\n",
    "print(arr.shape)\n",
    "arr = arr[:, np.where(np.abs(data[-1]-8) <= 1)[0]]\n",
    "print(arr.shape)\n",
    "arr = np.mean(arr, axis=1)\n",
    "print(arr.shape)\n",
    "plt.plot(arr)\n",
    "plt.title(\"corrélation par layer des zones des cortex auditifs et autres voxels du cluster 8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c7a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "np.random.seed(0)\n",
    "data = [np.argmax(corr_layers_voxels, axis=0) for corr_layers_voxels in corr_layers_voxels_models]\n",
    "\n",
    "\n",
    "arr = np.zeros(n_voxels)\n",
    "arr = arr * 0\n",
    "arr[np.where(np.abs(data[-1]-15) <= 2)] = 1\n",
    "\n",
    "imgtmp = nifti_masker.inverse_transform(arr)\n",
    "\n",
    "temp_filename = f'temppp_{0}.png'\n",
    "plotting.plot_img_on_surf(imgtmp,\n",
    "                        surf_mesh='fsaverage5',\n",
    "                        views=['lateral'],\n",
    "                        hemispheres=['left', 'right'],\n",
    "                        cmap='Spectral_r',\n",
    "                        vmax=1,\n",
    "                        symmetric_cbar=False,\n",
    "                        cbar_tick_format='%.2f',\n",
    "                        colorbar=True,\n",
    "                        title=\"Cluster layer 7, 8, 9, 12b\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239f7418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "np.random.seed(0)\n",
    "data = [np.argmax(corr_layers_voxels, axis=0) for corr_layers_voxels in corr_layers_voxels_models]\n",
    "\n",
    "\n",
    "arr = np.zeros(n_voxels)\n",
    "arr = arr * 0\n",
    "arr[np.where(np.abs(data[-1]-19) <= 2)] = 1\n",
    "\n",
    "imgtmp = nifti_masker.inverse_transform(arr)\n",
    "\n",
    "temp_filename = f'temppp_{0}.png'\n",
    "plotting.plot_img_on_surf(imgtmp,\n",
    "                        surf_mesh='fsaverage5',\n",
    "                        views=['lateral'],\n",
    "                        hemispheres=['left', 'right'],\n",
    "                        cmap='Spectral_r',\n",
    "                        vmax=1,\n",
    "                        symmetric_cbar=False,\n",
    "                        cbar_tick_format='%.2f',\n",
    "                        colorbar=True,\n",
    "                        title=\"Cluster layer 7, 8, 9, 12b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a00bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "np.random.seed(0)\n",
    "data = [np.mean(corr_layers_voxels, axis=0) for corr_layers_voxels in corr_layers_voxels_models]\n",
    "\n",
    "# Création des traces pour chaque distribution\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, dist in enumerate(data):\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=dist,\n",
    "            name=f'Time {i}',\n",
    "            visible=False,  # Masquer toutes les traces sauf la première\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Rendre la première trace visible\n",
    "fig.data[0].visible = True\n",
    "\n",
    "# Création des boutons pour le slider\n",
    "gsteps = []\n",
    "for i in range(len(data)):\n",
    "    gstep = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(data)},\n",
    "              {\"title\": f\"Distribution at Time {i}\"}],\n",
    "    )\n",
    "    gstep[\"args\"][0][\"visible\"][i] = True  # Rendre la trace actuelle visible\n",
    "    gsteps.append(gstep)\n",
    "\n",
    "sliders = [dict(\n",
    "    active=0,\n",
    "    currentvalue={\"prefix\": \"Time: \"},\n",
    "    pad={\"t\": 50},\n",
    "    steps=gsteps\n",
    ")]\n",
    "\n",
    "fig.update_layout(\n",
    "    sliders=sliders,\n",
    "    title=\"Evolution of Distribution Over Time\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579949c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "np.random.seed(0)\n",
    "data = [np.mean(corr_layers_voxels, axis=1) for corr_layers_voxels in corr_layers_voxels_models]\n",
    "data2 = [np.mean(d) for d in data]\n",
    "plt.plot(range(len(data2)), data2)\n",
    "plt.show()\n",
    "# Création des traces pour chaque distribution\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, dist in enumerate(data):\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=dist,\n",
    "            name=f'Time {i}',\n",
    "            visible=False,  # Masquer toutes les traces sauf la première\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Rendre la première trace visible\n",
    "fig.data[0].visible = True\n",
    "\n",
    "# Création des boutons pour le slider\n",
    "gsteps = []\n",
    "for i in range(len(data)):\n",
    "    gstep = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(data)},\n",
    "              {\"title\": f\"Distribution at Time {i}\"}],\n",
    "    )\n",
    "    gstep[\"args\"][0][\"visible\"][i] = True  # Rendre la trace actuelle visible\n",
    "    gsteps.append(gstep)\n",
    "\n",
    "sliders = [dict(\n",
    "    active=0,\n",
    "    currentvalue={\"prefix\": \"Time: \"},\n",
    "    pad={\"t\": 50},\n",
    "    steps=gsteps\n",
    ")]\n",
    "\n",
    "fig.update_layout(\n",
    "    sliders=sliders,\n",
    "    title=\"Evolution of Distribution Over Time\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480f5024-fa5a-4e92-a893-f117873b48de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean correlation for each voxel, for each model, using best layer for each voxel\n",
    "# n_models x n_voxels\n",
    "corr_voxels_models = []\n",
    "for corr_layers_voxels in corr_layers_voxels_models:\n",
    "    if corr_layers_voxels.size == 0:\n",
    "        # Handle empty array case, e.g., append a default value or skip\n",
    "        corr_voxels_models.append(np.nan)  # or any default value you prefer\n",
    "    else:\n",
    "        corr_voxels_models.append(np.max(corr_layers_voxels, axis=0))\n",
    "corr_voxels_models = np.array(corr_voxels_models)\n",
    "\n",
    "# mean correlation for each model, using best layer for each voxel, averaged over all voxels\n",
    "# n_voxels\n",
    "corr_models = np.array([np.mean(corr_voxels) for corr_voxels in corr_voxels_models])\n",
    "\n",
    "# mean correlation for each layer of each model, averaged over all voxels\n",
    "# n_models x n_layers \n",
    "corr_layers_models = [np.mean(corr_layers, axis=1) for corr_layers in corr_layers_voxels_models]\n",
    "# restrict to left and right hemisphere\n",
    "corr_l_models = corr_voxels_models[:,:n_voxels//2]\n",
    "corr_r_models = corr_voxels_models[:,n_voxels//2:]\n",
    "\n",
    "torch.save([model_names, corr_voxels_models, corr_models, corr_layers_models, corr_l_models, corr_r_models], 'metrics/' + \"12bmetrics.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98798600",
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = corr_l_models\n",
    "data1 = corr_r_models\n",
    "# Création des traces pour chaque distribution\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(len(data0)):\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=data0[i],\n",
    "            name=f'Left Step {steps[i]}',\n",
    "            visible=False,  # Masquer toutes les traces sauf les premières\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=data1[i],\n",
    "            name=f'Right Step {steps[i]}',\n",
    "            visible=False,  # Masquer toutes les traces sauf les premières\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Rendre les deux premières traces visibles\n",
    "fig.data[0].visible = True\n",
    "fig.data[1].visible = True\n",
    "\n",
    "# Création des boutons pour le slider\n",
    "gsteps = []\n",
    "for i in range(len(data0)):\n",
    "    gstep = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * (2 * len(data0))},\n",
    "              {\"title\": f\"Distribution at Time {steps[i]}\"}],\n",
    "    )\n",
    "    gstep[\"args\"][0][\"visible\"][2 * i] = True  # Rendre la trace actuelle de data0 visible\n",
    "    gstep[\"args\"][0][\"visible\"][2 * i + 1] = True  # Rendre la trace actuelle de data1 visible\n",
    "    gsteps.append(gstep)\n",
    "\n",
    "sliders = [dict(\n",
    "    active=0,\n",
    "    currentvalue={\"prefix\": \"Time: \"},\n",
    "    pad={\"t\": 50},\n",
    "    steps=gsteps\n",
    ")]\n",
    "\n",
    "fig.update_layout(\n",
    "    sliders=sliders,\n",
    "    title=\"Evolution of Distributions Over Time\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cce710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c88cd-1b19-45c0-8319-94cda25d366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left: red, right: green (as for port and starboard; should be colorblind compatible though)\n",
    "l_r_colors = sns.color_palette('colorblind', n_colors=4)[2:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0fc4dd-3a58-4a9c-ab2e-89eb6968b55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logspace(2,7,16)[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d76451",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ baselines ################################\n",
    "\n",
    "# look at random embeddings\n",
    "corr_random_emb_300 = []\n",
    "for seed in range(1,11):\n",
    "    model_name ='random_embedding_300d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr_random_emb_300.append(corr)\n",
    "corr_random_emb_300 = np.mean(corr_random_emb_300, axis=0)\n",
    "\n",
    "corr_random_emb_1024 = []\n",
    "for seed in range(1,11):\n",
    "    model_name ='random_embedding_1024d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr_random_emb_1024.append(corr)\n",
    "corr_random_emb_1024 = np.mean(corr_random_emb_1024, axis=0)\n",
    "\n",
    "corr2_random_emb_1024 = []\n",
    "for seed in range(11,21):\n",
    "    model_name ='random_embedding_1024d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr2_random_emb_1024.append(corr)\n",
    "corr2_random_emb_1024 = np.mean(corr2_random_emb_1024, axis=0)\n",
    "\n",
    "corr_random_vec_1024 = []\n",
    "for seed in range(1,9):\n",
    "    model_name ='random_vector_1024d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr_random_vec_1024.append(corr)\n",
    "corr_random_vec_1024 = np.mean(corr_random_vec_1024, axis=0)\n",
    "\n",
    "corr_lograndom_vec_1024 = []\n",
    "for seed in range(10,18):\n",
    "    model_name ='random_vector_1024d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr_lograndom_vec_1024.append(corr)\n",
    "corr_lograndom_vec_1024 = np.mean(corr_lograndom_vec_1024, axis=0)\n",
    "\n",
    "corr_exprandom_vec_1024 = []\n",
    "for seed in range(30,40):\n",
    "    model_name ='random_vector_1024d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr_exprandom_vec_1024.append(corr)\n",
    "    print(corr_exprandom_vec_1024)\n",
    "corr_exprandom_vec_1024 = np.mean(corr_exprandom_vec_1024, axis=0)\n",
    "\n",
    "corr_cauchyrandom_vec_1024 = []\n",
    "for seed in range(40,50):\n",
    "    model_name ='random_vector_1024d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr_cauchyrandom_vec_1024.append(corr)\n",
    "corr_cauchyrandom_vec_1024 = np.mean(corr_cauchyrandom_vec_1024, axis=0)\n",
    "\n",
    "corr_georandom_vec_1024 = []\n",
    "for seed in range(50,60):\n",
    "    model_name ='random_vector_1024d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr_georandom_vec_1024.append(corr)\n",
    "corr_georandom_vec_1024 = np.mean(corr_georandom_vec_1024, axis=0)\n",
    "\n",
    "corr_lograndom_emb_1024 = []\n",
    "for seed in range(20,28):\n",
    "    model_name ='random_embedding_1024d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr_lograndom_emb_1024.append(corr)\n",
    "corr_lograndom_emb_1024 = np.mean(corr_lograndom_emb_1024, axis=0)\n",
    "\n",
    "corr_exprandom_emb_1024 = []\n",
    "for seed in range(30,39):\n",
    "    model_name ='random_embedding_1024d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr_exprandom_emb_1024.append(corr)\n",
    "corr_exprandom_emb_1024 = np.mean(corr_exprandom_emb_1024, axis=0)\n",
    "\n",
    "corr_cauchyrandom_emb_1024 = []\n",
    "for seed in range(40,49):\n",
    "    model_name ='random_embedding_1024d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr_cauchyrandom_emb_1024.append(corr)\n",
    "corr_cauchyrandom_emb_1024 = np.mean(corr_cauchyrandom_emb_1024, axis=0)\n",
    "\n",
    "corr_georandom_emb_1024 = []\n",
    "for seed in range(50,59):\n",
    "    model_name ='random_embedding_1024d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr_georandom_emb_1024.append(corr)\n",
    "corr_georandom_emb_1024 = np.mean(corr_georandom_emb_1024, axis=0)\n",
    "\n",
    "# GloVe\n",
    "model_name ='glove'\n",
    "filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "with open(filename, 'rb') as f:\n",
    "    corr_glove = joblib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5541087-4884-45be-acb6-0e6c9701d554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_xy(xvalue, yvalue, xlabel=None, ylabel=None, logx=False, invert_xaxis=False, figsize=(6.4, 4.8), title=\"\"):        \n",
    "    xvalue = np.array(xvalue)\n",
    "    xvalue[xvalue<1] = 1\n",
    "    fh = plt.figure(figsize=figsize)\n",
    "    ax = plt.subplot(111)\n",
    "    fh.suptitle(title)\n",
    "    sns.scatterplot(x=xvalue,\n",
    "                    y=yvalue, ax=ax);\n",
    "    if logx:\n",
    "        ax.set_xscale('log')\n",
    "    if invert_xaxis:\n",
    "        ax.invert_xaxis()\n",
    "    ax.set_xlabel(xlabel)      \n",
    "    ax.set_ylabel(ylabel)\n",
    "    if logx:\n",
    "         r, p = pearsonr(np.log(xvalue), yvalue)\n",
    "    else:\n",
    "         r, p = pearsonr(xvalue, yvalue)\n",
    "   \n",
    "    # fh.text(0.15, 0.85,'$r={:.2f}$\\n$p={:.1e}$'.format(r,p),\n",
    "    #         ha='left', va='top', fontsize=11)\n",
    "    return fh\n",
    "\n",
    "def pvalue2str(pvalue):\n",
    "    if pvalue <= 0.001:\n",
    "        return '***'\n",
    "    elif pvalue <= 0.01:\n",
    "        return '**'\n",
    "    elif pvalue <= 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return 'ns'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71abb21f-15be-4a38-a9c5-1723bdfc237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## Using reliable voxels: best 25% voxels ##########################################\n",
    "\n",
    "n_trials_split = 10\n",
    "filename = 'corr_group_split_{}trials.gz'.format(n_trials_split)\n",
    "corr_split = joblib.load(filename)\n",
    "corr_split_mean = np.mean(corr_split, axis=0)\n",
    "\n",
    "is_voxel_reliable = corr_split_mean > np.percentile(corr_split_mean, 75)\n",
    "nois_voxel_reliable = corr_split_mean < np.percentile(corr_split_mean, 1/10_000)\n",
    "print(nois_voxel_reliable)\n",
    "print(np.argmax(nois_voxel_reliable))\n",
    "#### rv for reliable voxels\n",
    "\n",
    "# mean correlation for each voxel, for each model, using best layer for each voxel\n",
    "# n_models x n_voxels\n",
    "corr_voxels_models_rv = np.array([np.max(corr_layers_voxels[:,is_voxel_reliable], axis=0)\n",
    "                                  for corr_layers_voxels in corr_layers_voxels_models])\n",
    "\n",
    "# mean correlation for each model, using best layer for each voxel, averaged over all voxels\n",
    "# n_voxels\n",
    "corr_models_rv = np.array([np.mean(corr_voxels[is_voxel_reliable]) for corr_voxels in corr_voxels_models])\n",
    "nocorr_models_rv = np.array([np.mean(corr_voxels[67]) for corr_voxels in corr_voxels_models])\n",
    "nocorr_models_rv = np.array(corr_layers_voxels_models[-1])\n",
    "print(\"aaaa\", np.mean(corr_models_rv))\n",
    "\n",
    "max_corr_per_voxel = np.max(corr_layers_voxels_models[-1], axis=0)\n",
    "num_voxels = corr_layers_voxels_models[-1].shape[1]\n",
    "n_pire_voxels = int(0.05 * num_voxels)\n",
    "pire_voxel_indices = np.argsort(max_corr_per_voxel)[-n_pire_voxels:]\n",
    "argmax_layers_pire_voxels = np.argmax(corr_layers_voxels_models[-1][:, pire_voxel_indices], axis=0)\n",
    "print(\"Indices des pires voxels :\", pire_voxel_indices)\n",
    "print(\"Argmax (layer) des pires voxels :\", argmax_layers_pire_voxels)\n",
    "print(np.mean(argmax_layers_pire_voxels))\n",
    "# mean correlation for each layer of each model, averaged over all voxels\n",
    "# n_models x n_layers \n",
    "corr_layers_models_rv = [np.mean(corr_layers[:, is_voxel_reliable], axis=1) for corr_layers in corr_layers_voxels_models]\n",
    "\n",
    "argmax_layers_all_voxels = np.argmax(corr_layers_voxels_models[-1], axis=0)\n",
    "voxel_indices_argmax_gt_30 = np.where(np.abs(argmax_layers_all_voxels-7) <= 1)[0]\n",
    "ppp = np.zeros(len(corr_voxels_models[-1]))\n",
    "ppp = np.array(ppp)\n",
    "ppp[voxel_indices_argmax_gt_30] = 1\n",
    "imgtmp = nifti_masker.inverse_transform(ppp)\n",
    "display = plotting.plot_glass_brain(imgtmp, threshold=0., display_mode='lyrz', \n",
    "                          vmin=0., cmap='Spectral_r', \n",
    "                          plot_abs=True)\n",
    "\n",
    "max_corr_for_selected_voxels = np.max(np.array(corr_layers_voxels_models[-1])[:, voxel_indices_argmax_gt_30], axis=0)\n",
    "print(max_corr_for_selected_voxels)\n",
    "\n",
    "# restrict to left and right hemisphere\n",
    "# n_models x n_voxels//2\n",
    "corr_l_models_rv = corr_l_models[:,is_voxel_reliable[:n_voxels//2]]\n",
    "corr_r_models_rv = corr_r_models[:,is_voxel_reliable[n_voxels//2:]]\n",
    "\n",
    "fh = plt.figure(figsize=(5,3))\n",
    "ax = plt.subplot(111)\n",
    "sns.kdeplot(corr_split_mean, cut=0., ax=ax)\n",
    "plt.axvline(np.percentile(corr_split_mean, 75), ls='--', c='0.4');\n",
    "plt.xlabel('correlation')\n",
    "plt.ylabel('density')\n",
    "plt.show()\n",
    "\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'reliable_voxels_distribution.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))\n",
    "\n",
    "imgtmp = nifti_masker.inverse_transform(corr_split_mean)\n",
    "fh = plt.figure(figsize=(12,3))\n",
    "ax = plt.subplot(111)\n",
    "display = plotting.plot_glass_brain(imgtmp, threshold=0., display_mode='lyrz', \n",
    "                          vmin=0., cmap='Spectral_r', \n",
    "                          plot_abs=True, colorbar=True, axes=ax)\n",
    "display.add_contours(imgtmp, levels=[np.percentile(corr_split_mean, 75)], colors='0.2', linewidths=1.2, alpha=0.9, linestyles='dashed')\n",
    "\n",
    "display._colorbar_ax.set_yticks([0., np.percentile(corr_split_mean, 75), np.max(corr_split_mean)])\n",
    "ylim = display._colorbar_ax.get_ylim()  \n",
    "ax2 = display._colorbar_ax.twinx()\n",
    "ax2.set_ylim(ylim)\n",
    "ax2.set_yticks([0., np.percentile(corr_split_mean, 75), np.max(corr_split_mean)], ['0%', '75%', '100%'])\n",
    "ax2.yaxis.set_tick_params(width=0)\n",
    "#display._cbar._\n",
    "ax2.axhline(np.percentile(corr_split_mean, 75), ls='--', lw=1.2, color='0.2')\n",
    "\n",
    "plotting.show() \n",
    "\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'reliable_voxels_75.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde8fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "np.random.seed(0)\n",
    "print(is_voxel_reliable)\n",
    "data = [np.argmax(corr_layers_voxels[:, is_voxel_reliable], axis=0) for corr_layers_voxels in corr_layers_voxels_models]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, dist in enumerate(data):\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=dist,\n",
    "            name=f'Time {i}',\n",
    "            visible=False,  # Masquer toutes les traces sauf la première\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Rendre la première trace visible\n",
    "fig.data[0].visible = True\n",
    "\n",
    "# Création des boutons pour le slider\n",
    "gsteps = []\n",
    "for i in range(len(data)):\n",
    "    gstep = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(data)},\n",
    "              {\"title\": f\"Distribution at Time {i}\"}],\n",
    "    )\n",
    "    gstep[\"args\"][0][\"visible\"][i] = True  # Rendre la trace actuelle visible\n",
    "    gsteps.append(gstep)\n",
    "\n",
    "sliders = [dict(\n",
    "    active=0,\n",
    "    currentvalue={\"prefix\": \"Time: \"},\n",
    "    pad={\"t\": 50},\n",
    "    steps=gsteps\n",
    ")]\n",
    "\n",
    "fig.update_layout(\n",
    "    sliders=sliders,\n",
    "    title=\"Evolution of Distribution Over Time\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd588d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [np.argmax(corr_layers_voxels[:, :], axis=0) for corr_layers_voxels in corr_layers_voxels_models][-1]\n",
    "data = np.array(data)\n",
    "print(data.shape)\n",
    "imgtmp = nifti_masker.inverse_transform(data)\n",
    "\n",
    "vmax = 31\n",
    "\n",
    "fh, axes = plotting.plot_img_on_surf(imgtmp,\n",
    "                                     surf_mesh='fsaverage5',\n",
    "                                     views=['lateral'],\n",
    "                                     hemispheres=['left', 'right'],\n",
    "                                     vmin=0., vmax=vmax,\n",
    "                                     cmap='Spectral_r',\n",
    "                                     symmetric_cbar=False,\n",
    "                                     cbar_tick_format='%.2f',\n",
    "                                     colorbar=True,\n",
    "                                     title='trained best layer')\n",
    "for ax in axes[0:2]:\n",
    "    ax.set_box_aspect(None, zoom=1.45)\n",
    "fh.set_size_inches(7, 4.3)\n",
    "plotting.show()\n",
    "\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'brain_best_over_random_emb.pdf'), bbox_inches='tight', \n",
    "               transparent=True, facecolor=(1,1,1,0))\n",
    "    \n",
    "######## worst model ########\n",
    "\n",
    "data = [np.argmax(corr_layers_voxels[:, :], axis=0) for corr_layers_voxels in corr_layers_voxels_models][0]\n",
    "imgtmp = nifti_masker.inverse_transform(data)\n",
    "\n",
    "fh, axes = plotting.plot_img_on_surf(imgtmp,\n",
    "                                     surf_mesh='fsaverage5',\n",
    "                                     views=['lateral'],\n",
    "                                     hemispheres=['left', 'right'],\n",
    "                                     vmin=0., vmax=vmax,\n",
    "                                     cmap='Spectral_r',\n",
    "                                     symmetric_cbar=False,\n",
    "                                     cbar_tick_format='%.2f',\n",
    "                                     colorbar=True,\n",
    "                                     title=\"untrained\")\n",
    "for ax in axes[0:2]:\n",
    "    ax.set_box_aspect(None, zoom=1.45)\n",
    "fh.set_size_inches(7, 4.3)\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64688c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from nilearn import plotting\n",
    "\n",
    "# Les données doivent être préparées à l'avance\n",
    "# steps = [1_000, *range(10_000, 140_000, 10_000), 143000]\n",
    "# corr_models_rv = [...]\n",
    "vmax = 32\n",
    "data = [np.argmax(corr_layers_voxels[:, :], axis=0) for corr_layers_voxels in corr_layers_voxels_models]\n",
    "for step_idx in range(len(steps)):\n",
    "    idx_best_model = step_idx\n",
    "    print(f'Generating image for step {steps[step_idx]}')\n",
    "    imgtmp = nifti_masker.inverse_transform(data[step_idx])\n",
    "    \n",
    "    # Enregistrez l'image directement sans utiliser axes\n",
    "    temp_filename = f'temppp_{step_idx}.png'\n",
    "    plotting.plot_img_on_surf(imgtmp,\n",
    "                              surf_mesh='fsaverage5',\n",
    "                              views=['lateral'],\n",
    "                              hemispheres=['left', 'right'],\n",
    "                              vmin=0., vmax=vmax,\n",
    "                              cmap='Spectral_r',\n",
    "                              symmetric_cbar=False,\n",
    "                              cbar_tick_format='%.2f',\n",
    "                              colorbar=True,\n",
    "                              title=str(steps[step_idx]))\n",
    "    \n",
    "    plt.savefig(temp_filename)\n",
    "    plt.close()\n",
    "\n",
    "# Optionnel : sauvegardez toutes les images sous forme de GIF pour vérification\n",
    "images = [imageio.imread(f'temppp_{i}.png') for i in range(len(steps))]\n",
    "imageio.mimsave('brain_correlations.gif', images, duration=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dbce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Créez un widget slider\n",
    "step_slider = widgets.IntSlider(min=0, max=len(steps)-1, step=1, description='Step Index')\n",
    "\n",
    "# Fonction pour afficher une image donnée par l'indice du slider\n",
    "def show_image(step_idx):\n",
    "    display(Image(filename=f'temppp_{step_idx}.png'))\n",
    "\n",
    "# Connectez le slider à la fonction de plot\n",
    "interactive_plot = widgets.interactive(show_image, step_idx=step_slider)\n",
    "display(interactive_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68bbb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "np.random.seed(0)\n",
    "data = [np.mean(corr_layers_voxels[:, is_voxel_reliable], axis=0) for corr_layers_voxels in corr_layers_voxels_models]\n",
    "print(np.shape(data))\n",
    "# Création des traces pour chaque distribution\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, dist in enumerate(data):\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=dist,\n",
    "            name=f'Time {i}',\n",
    "            visible=False,  # Masquer toutes les traces sauf la première\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Rendre la première trace visible\n",
    "fig.data[0].visible = True\n",
    "\n",
    "# Création des boutons pour le slider\n",
    "gsteps = []\n",
    "for i in range(len(data)):\n",
    "    gstep = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(data)},\n",
    "              {\"title\": f\"Distribution at Time {i}\"}],\n",
    "    )\n",
    "    gstep[\"args\"][0][\"visible\"][i] = True  # Rendre la trace actuelle visible\n",
    "    gsteps.append(gstep)\n",
    "\n",
    "sliders = [dict(\n",
    "    active=0,\n",
    "    currentvalue={\"prefix\": \"Time: \"},\n",
    "    pad={\"t\": 50},\n",
    "    steps=gsteps\n",
    ")]\n",
    "\n",
    "fig.update_layout(\n",
    "    sliders=sliders,\n",
    "    title=\"Evolution of Distribution Over Time\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22432e1a-54d9-47a0-9907-27ffd7d73200",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = plot_xy(steps, [i for i in corr_models], \n",
    "             xlabel='epoch', ylabel='brain correlation', \n",
    "             logx=True, title='brain correlation per log of training epoch (pythia 12b)')\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'llms_params_corr.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fd1385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import expit  # C'est la fonction sigmoid\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Fonction sigmoïde modélisée\n",
    "def sigmoid_model(x, a, b, lambda_):\n",
    "    return a + abs(lambda_) * expit(abs(1) * x + b)\n",
    "\n",
    "# Estimation des paramètres pour chaque voxel\n",
    "def estimate_parameters(layers, arr, tresh=0):\n",
    "    params = []\n",
    "    for voxel_data in tqdm(arr.T):  # On transpose l'array pour itérer sur les voxels\n",
    "        initial_guess = [1, 1, 1]\n",
    "        if True:\n",
    "            if tresh >= 0:\n",
    "                if np.max(voxel_data) > tresh:\n",
    "                    popt, _ = curve_fit(sigmoid_model, layers, voxel_data, p0=initial_guess, maxfev=50000)\n",
    "                    # x_fit = np.linspace(min(layers), max(layers), 100)\n",
    "                    # y_fit = sigmoid_model(x_fit, *popt)\n",
    "                    # plt.scatter(layers, voxel_data, label='Données réelles', color='red')\n",
    "                    # plt.plot(x_fit, y_fit, label='Ajustement sigmoïde', color='blue')\n",
    "                    # plt.show()\n",
    "                    # input()\n",
    "                    # break\n",
    "                else:\n",
    "                    popt = [0, 0, 0]\n",
    "            else:\n",
    "                if np.max(voxel_data) < -tresh:\n",
    "                    popt, _ = curve_fit(sigmoid_model, layers, voxel_data, p0=initial_guess, maxfev=50000)\n",
    "                else:\n",
    "                    popt = [0, 0, 0]\n",
    "        # except Exception:\n",
    "        #     popt = [0, 0, 0]\n",
    "        params.append(np.abs(popt))\n",
    "    return np.array(params)\n",
    "arr = np.array(corr_voxels_models) - corr_random_emb_1024\n",
    "# print(arr)\n",
    "# Exemple d'utilisation :\n",
    "layers = np.log(steps)\n",
    "layers[0] = - 10\n",
    "params_voxels = estimate_parameters(layers, arr, 0.)\n",
    "print(np.array(params_voxels).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf488d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = np.array(params_voxels)[:, 1]\n",
    "data = offset\n",
    "imgtmp = nifti_masker.inverse_transform(data)\n",
    "plotting.plot_img_on_surf(imgtmp,\n",
    "                          surf_mesh='fsaverage5',\n",
    "                          views=['lateral'],\n",
    "                          hemispheres=['left', 'right'],\n",
    "                          cmap='Spectral_r',\n",
    "                          vmin=5, vmax=7.5,\n",
    "                          symmetric_cbar=False,\n",
    "                          cbar_tick_format='%.2f',\n",
    "                          colorbar=True,\n",
    "                          title=\"offset de la sigmoid modélisant l'apprentissage par layer\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b03384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets, surface, plotting\n",
    "from nilearn.input_data import NiftiMasker\n",
    "import numpy as np\n",
    "\n",
    "fsaverage = datasets.fetch_surf_fsaverage()\n",
    "data_voxels = np.array(params_voxels)[:, 1]\n",
    "img_data = nifti_masker.inverse_transform(data_voxels)\n",
    "\n",
    "texture_left = surface.vol_to_surf(img_data, fsaverage['pial_left'])\n",
    "texture_right = surface.vol_to_surf(img_data, fsaverage['pial_right'])\n",
    "\n",
    "plotting.plot_surf(fsaverage['infl_left'], texture_left, hemi='left',\n",
    "                   cmap='Spectral_r', colorbar=True, title='Offset apprentissage : Surface gauche',\n",
    "                   vmin=5, vmax=8)\n",
    "\n",
    "plotting.plot_surf(fsaverage['infl_right'], texture_right, hemi='right',\n",
    "                   cmap='Spectral_r', colorbar=True, title='Offset apprentissage : Surface droite',\n",
    "                   vmin=5, vmax=8)\n",
    "\n",
    "plotting.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d07ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import expit  # C'est la fonction sigmoid\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Fonction sigmoïde modélisée\n",
    "def sigmoid_model(x, a, b, lambda_):\n",
    "    return a + abs(lambda_) * expit(abs(1) * x + b)\n",
    "\n",
    "# Estimation des paramètres pour chaque voxel\n",
    "def estimate_parameters(layers, arr, tresh=0):\n",
    "    params = []\n",
    "    for voxel_data in tqdm(arr.T):  # On transpose l'array pour itérer sur les voxels\n",
    "        initial_guess = [1, 1, 1]\n",
    "        if True:\n",
    "            if tresh >= 0:\n",
    "                if np.max(voxel_data) > tresh:\n",
    "                    popt, _ = curve_fit(sigmoid_model, layers, voxel_data, p0=initial_guess, maxfev=50000)\n",
    "                    # x_fit = np.linspace(min(layers), max(layers), 100)\n",
    "                    # y_fit = sigmoid_model(x_fit, *popt)\n",
    "                    # plt.scatter(layers, voxel_data, label='Données réelles', color='red')\n",
    "                    # plt.plot(x_fit, y_fit, label='Ajustement sigmoïde', color='blue')\n",
    "                    # plt.show()\n",
    "                    # input()\n",
    "                    # break\n",
    "                else:\n",
    "                    popt = [0, 0, 0]\n",
    "            else:\n",
    "                if np.max(voxel_data) < -tresh:\n",
    "                    popt, _ = curve_fit(sigmoid_model, layers, voxel_data, p0=initial_guess, maxfev=50000)\n",
    "                else:\n",
    "                    popt = [0, 0, 0]\n",
    "        # except Exception:\n",
    "        #     popt = [0, 0, 0]\n",
    "        params.append(np.abs(popt))\n",
    "    return np.array(params)\n",
    "arr = np.array(corr_layers_voxels_models)[:, -1, :] - corr_random_emb_1024\n",
    "# print(arr)\n",
    "# Exemple d'utilisation :\n",
    "layers = np.log(steps)\n",
    "layers[0] = - 10\n",
    "params_voxels = estimate_parameters(layers, arr, 0.)\n",
    "print(sum(params_voxels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20a385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convertir les params_voxels en un tableau numpy\n",
    "params_voxels = np.array(params_voxels)\n",
    "\n",
    "# Extraire les colonnes x1, x2, x3\n",
    "x1 = params_voxels[:, 0] * 50\n",
    "x2 = params_voxels[:, 1]\n",
    "x3 = params_voxels[:, 2] * 20\n",
    "\n",
    "# Créer des masques pour filtrer les valeurs égales à 0\n",
    "mask = (x1 != 0) & (x2 != 0) & (x3 != 0)\n",
    "\n",
    "# Appliquer le masque pour filtrer les valeurs nulles\n",
    "x1_filtered = x1[mask]\n",
    "x2_filtered = x2[mask]\n",
    "x3_filtered = x3[mask]\n",
    "\n",
    "# Calculer la KDE avec les données filtrées\n",
    "kde_x1 = gaussian_kde(x1_filtered, bw_method=0.005)\n",
    "kde_x2 = gaussian_kde(x2_filtered, bw_method=0.001)\n",
    "kde_x3 = gaussian_kde(x3_filtered, bw_method=0.00007)\n",
    "# Définir un intervalle de points pour l'évaluation de la densité\n",
    "x_vals = np.linspace(-1, 10, 1_000)\n",
    "\n",
    "# Tracer les densités\n",
    "plt.plot(x_vals, kde_x1(x_vals), label='bias', lw=2)\n",
    "plt.plot(x_vals, kde_x2(x_vals), label='offset', lw=2)\n",
    "plt.plot(x_vals, kde_x3(x_vals), label='5 * yscale', lw=2)\n",
    "\n",
    "# Ajouter légendes et titre\n",
    "plt.legend()\n",
    "plt.title(\"Densité lissée des paramètres. y = yscale * sig(xscale * x + offset)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9b25f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convertir les params_voxels en un tableau numpy\n",
    "params_voxels = np.array(params_voxels)\n",
    "\n",
    "# Extraire les colonnes x1, x2, x3\n",
    "x1 = params_voxels[:, 0] * 10\n",
    "x2 = params_voxels[:, 1]\n",
    "x3 = params_voxels[:, 2] * 20\n",
    "\n",
    "# Créer des masques pour filtrer les valeurs égales à 0\n",
    "mask = (x1 != 0) & (x2 != 0) & (x3 != 0)\n",
    "\n",
    "# Appliquer le masque pour filtrer les valeurs nulles\n",
    "x1_filtered = x1[mask]\n",
    "x2_filtered = x2[mask]\n",
    "x3_filtered = x3[mask]\n",
    "\n",
    "# Calculer la KDE avec les données filtrées\n",
    "kde_x1 = gaussian_kde(x1_filtered, bw_method=0.005)\n",
    "kde_x2 = gaussian_kde(x2_filtered, bw_method=0.001)\n",
    "kde_x3 = gaussian_kde(x3_filtered, bw_method=0.00007)\n",
    "# Définir un intervalle de points pour l'évaluation de la densité\n",
    "x_vals = np.linspace(-1, 10, 1_000)\n",
    "\n",
    "# Tracer les densités\n",
    "plt.plot(x_vals, kde_x1(x_vals), label='bias', lw=2)\n",
    "plt.plot(x_vals, kde_x2(x_vals), label='offset', lw=2)\n",
    "# plt.plot(x_vals, kde_x3(x_vals), label='5 * yscale', lw=2)\n",
    "\n",
    "# Ajouter légendes et titre\n",
    "plt.legend()\n",
    "plt.title(\"Densité lissée des paramètres. y = yscale * sig(xscale * x + offset)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb314e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convertir les params_voxels en un tableau numpy\n",
    "params_voxels = np.array(params_voxels)\n",
    "\n",
    "# Extraire les colonnes x1, x2, x3\n",
    "x1 = params_voxels[:, 1]\n",
    "x2 = params_voxels[:, 1]\n",
    "x3 = params_voxels[:, 2]\n",
    "\n",
    "# Créer des masques pour filtrer les valeurs égales à 0\n",
    "mask = (x1 != 0) & (x2 != 0) & (x3 != 0)\n",
    "\n",
    "# Appliquer le masque pour filtrer les valeurs nulles\n",
    "x1_filtered = x1[mask]\n",
    "x2_filtered = x2[mask]\n",
    "x3_filtered = x3[mask] * 5\n",
    "\n",
    "# Calculer la KDE avec les données filtrées\n",
    "kde_x1 = gaussian_kde(x1_filtered, bw_method=0.005)\n",
    "kde_x2 = gaussian_kde(x2_filtered, bw_method=0.005)\n",
    "kde_x3 = gaussian_kde(x3_filtered, bw_method=0.05)\n",
    "# Définir un intervalle de points pour l'évaluation de la densité\n",
    "x_vals = np.linspace(0, 10, 10_000)\n",
    "\n",
    "# Tracer les densités\n",
    "# plt.plot(x_vals, kde_x1(x_vals), label='5 * xscale', lw=2)\n",
    "plt.plot(x_vals, kde_x2(x_vals), label='offset', lw=2)\n",
    "plt.plot(x_vals, kde_x3(x_vals), label='5 * yscale', lw=2)\n",
    "\n",
    "# Ajouter légendes et titre\n",
    "plt.legend()\n",
    "plt.title(\"Densité lissée des paramètres. y = yscale * sig(xscale * x + offset)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cbdae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convertir les params_voxels en un tableau numpy\n",
    "params_voxels = np.array(params_voxels)\n",
    "\n",
    "# Extraire les colonnes x1, x2, x3\n",
    "x1 = params_voxels[:, 1]\n",
    "x2 = params_voxels[:, 1]\n",
    "x3 = params_voxels[:, 2]\n",
    "\n",
    "# Créer des masques pour filtrer les valeurs égales à 0\n",
    "mask = (x1 != 0) & (x2 != 0) & (x3 != 0)\n",
    "\n",
    "# Appliquer le masque pour filtrer les valeurs nulles\n",
    "x1_filtered = x1[mask]\n",
    "x2_filtered = x2[mask]\n",
    "x3_filtered = x3[mask] * 5\n",
    "\n",
    "# Calculer la KDE avec les données filtrées\n",
    "kde_x1 = gaussian_kde(x1_filtered, bw_method=0.005)\n",
    "kde_x2 = gaussian_kde(x2_filtered, bw_method=0.005)\n",
    "kde_x3 = gaussian_kde(x3_filtered, bw_method=0.05)\n",
    "# Définir un intervalle de points pour l'évaluation de la densité\n",
    "x_vals = np.linspace(0, 10, 10_000)\n",
    "\n",
    "# Tracer les densités\n",
    "# plt.plot(x_vals, kde_x1(x_vals), label='5 * xscale', lw=2)\n",
    "plt.plot(x_vals, kde_x2(x_vals), label='offset', lw=2)\n",
    "plt.plot(x_vals, kde_x3(x_vals), label='5 * yscale', lw=2)\n",
    "\n",
    "# Ajouter légendes et titre\n",
    "plt.legend()\n",
    "plt.title(\"Densité lissée des paramètres. y = yscale * sig(xscale * x + offset)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ca6e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convertir les params_voxels en un tableau numpy\n",
    "params_voxels = np.array(params_voxels)\n",
    "\n",
    "# Extraire les colonnes x1, x2, x3\n",
    "x1 = params_voxels[:, 0]\n",
    "x2 = params_voxels[:, 1]\n",
    "x3 = params_voxels[:, 2]\n",
    "\n",
    "# Créer des masques pour filtrer les valeurs égales à 0\n",
    "mask = (x1 != 0) & (x2 != 0) & (x3 != 0)\n",
    "\n",
    "# Appliquer le masque pour filtrer les valeurs nulles\n",
    "x1_filtered = x1[mask] * 5\n",
    "x2_filtered = x2[mask]\n",
    "x3_filtered = x3[mask] * 5\n",
    "\n",
    "# Calculer la KDE avec les données filtrées\n",
    "kde_x1 = gaussian_kde(x1_filtered, bw_method=0.005)\n",
    "kde_x2 = gaussian_kde(x2_filtered, bw_method=0.005)\n",
    "kde_x3 = gaussian_kde(x3_filtered, bw_method=0.05)\n",
    "# Définir un intervalle de points pour l'évaluation de la densité\n",
    "x_vals = np.linspace(0, 5, 10_000)\n",
    "\n",
    "# Tracer les densités\n",
    "plt.plot(x_vals, kde_x1(x_vals), label='5 * xscale', lw=2)\n",
    "plt.plot(x_vals, kde_x2(x_vals), label='offset', lw=2)\n",
    "plt.plot(x_vals, kde_x3(x_vals), label='5 * yscale', lw=2)\n",
    "\n",
    "# Ajouter légendes et titre\n",
    "plt.legend()\n",
    "plt.title(\"Densité lissée des paramètres. y = yscale * sig(xscale * x + offset)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd23f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tracer le scatter plot\n",
    "plt.scatter(x2_filtered, x3_filtered)\n",
    "print(np.mean(x3_filtered))\n",
    "plt.xlim([0, 15])\n",
    "plt.ylim([0, 10])\n",
    "# Ajouter des titres et labels\n",
    "plt.title(\"Scatter plot entre l'offset et y_scale ; pas de filtrage\")\n",
    "plt.xlabel(\"offset\")\n",
    "plt.ylabel(\"50 * yscale\")\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2142e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tracer le scatter plot\n",
    "plt.scatter(x2_filtered, x3_filtered)\n",
    "print(np.mean(x3_filtered))\n",
    "plt.xlim([0, 15])\n",
    "plt.ylim([0, 10])\n",
    "# Ajouter des titres et labels\n",
    "plt.title(\"Scatter plot entre xscale et offset avec filtrage des valeurs > 50 en absolu\")\n",
    "plt.xlabel(\"offset\")\n",
    "plt.ylabel(\"5 * yscale\")\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5812aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(np.argmax(corr_lograndom_emb_1024))\n",
    "\n",
    "# Tracer le scatter plot\n",
    "plt.scatter(x2, x3)\n",
    "# plt.scatter(x2[sorted_indices[:300]], x3[sorted_indices[:300]])\n",
    "# plt.scatter(x2[np.where(np.abs(x2-6.7) > 1.4)], x3[np.where(np.abs(x2-6.7) > 1.4)])\n",
    "plt.scatter(x2[len(x2)//2:], x3[len(x2)//2:])\n",
    "# plt.scatter(x2[:len(x2)//2], x3[:len(x2)//2])\n",
    "print(np.mean(x3_filtered))\n",
    "plt.xlim([0, 15])\n",
    "plt.ylim([0, 10])\n",
    "# Ajouter des titres et labels\n",
    "plt.title(\"Scatter plot entre xscale et offset. En orange, l'hémisphère doite\")\n",
    "plt.xlabel(\"offset\")\n",
    "plt.ylabel(\"5 * yscale\")\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ddab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices = np.argsort(corr_lograndom_emb_1024)[::-1]\n",
    "\n",
    "# Get the index of the 100th largest element (since indexing starts at 0, we take 99th)\n",
    "hundredth_argmax = sorted_indices[99]\n",
    "\n",
    "hundredth_argmax\n",
    "w = np.where(x1 > 0)\n",
    "arr = np.zeros(n_voxels)\n",
    "arr[np.array(sorted_indices[:300])] = 100\n",
    "arr = arr * 0\n",
    "arr[np.where(x2-6.7 > 1.4)] = 1\n",
    "arr = arr * 0\n",
    "arr[np.where(np.abs(x3) < 2)] = 1\n",
    "\n",
    "arr = arr * 0\n",
    "arr[len(arr)//2:] = 1\n",
    "\n",
    "imgtmp = nifti_masker.inverse_transform(arr)\n",
    "\n",
    "temp_filename = f'temppp_{step_idx}.png'\n",
    "plotting.plot_img_on_surf(imgtmp,\n",
    "                        surf_mesh='fsaverage5',\n",
    "                        views=['lateral'],\n",
    "                        hemispheres=['left', 'right'],\n",
    "                        cmap='Spectral_r',\n",
    "                        vmax=1,\n",
    "                        symmetric_cbar=False,\n",
    "                        cbar_tick_format='%.2f',\n",
    "                        colorbar=True,\n",
    "                        title=\"aires a grand offset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f529b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices = np.argsort(corr_voxels_models[-1])[::-1]\n",
    "\n",
    "# Get the index of the 100th largest element (since indexing starts at 0, we take 99th)\n",
    "hundredth_argmax = sorted_indices[99]\n",
    "\n",
    "hundredth_argmax\n",
    "w = np.where(x1 > 0)\n",
    "arr = np.zeros(n_voxels)\n",
    "arr[np.array(sorted_indices[:300])] = 1\n",
    "imgtmp = nifti_masker.inverse_transform(arr)\n",
    "\n",
    "temp_filename = f'temppp_{step_idx}.png'\n",
    "plotting.plot_img_on_surf(imgtmp,\n",
    "                        surf_mesh='fsaverage5',\n",
    "                        views=['lateral'],\n",
    "                        hemispheres=['left', 'right'],\n",
    "                        cmap='Spectral_r',\n",
    "                        symmetric_cbar=False,\n",
    "                        cbar_tick_format='%.2f',\n",
    "                        colorbar=True,\n",
    "                        title=\"coucou\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00452e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Créer une figure et une grille de sous-plots\n",
    "fig, axs = plt.subplots(3, 3, figsize=(10, 10))\n",
    "\n",
    "# Données pour les plots (exemple)\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = np.sin(x)\n",
    "tresh = [0, 0.1, 0.3]\n",
    "\n",
    "# Légendes pour les lignes et les colonnes\n",
    "row_labels = ['all', 'max corr > 0.1', 'max corr > 0.3']\n",
    "col_labels = ['x=xscale * y=offset', 'x=xscale * y=yscale', 'x=offset * y=yscale']\n",
    "\n",
    "# Tracer les plots et ajouter les légendes\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        arr = np.array(corr_layers_voxels_models)[:, -1, :]\n",
    "        layers = np.arange(arr.shape[0])\n",
    "        data = estimate_parameters(layers, arr, tresh[i])\n",
    "        x1 = data[:, 0]\n",
    "        x2 = data[:, 1]\n",
    "        x3 = data[:, 2]\n",
    "        mask = (np.abs(x1) <= 1) & (np.abs(x2) <= 1) & (np.abs(x1) > 0.001) & (np.abs(x2) > 0.001) & (np.abs(x3) <= 1)\n",
    "        x1_filtered = np.abs(x1[mask])\n",
    "        x2_filtered = np.abs(x2[mask])\n",
    "        x3_filtered = np.abs(x3[mask])\n",
    "        if j == 0:\n",
    "            x = x1_filtered * 5\n",
    "            y = x2_filtered\n",
    "        elif j == 1:\n",
    "            x = x1_filtered * 5\n",
    "            y = x3_filtered * 5\n",
    "        else:\n",
    "            x = x3_filtered * 5\n",
    "            y = x2_filtered\n",
    "        # axs[i, j].scatter(x, y)\n",
    "        sns.kdeplot(x=x, y=y, fill=True, cmap=\"Blues\", thresh=0, levels=100, ax=axs[i, j], bw_adjust=0.5)\n",
    "        axs[i, j].set_xlim(0, 5)\n",
    "        axs[i, j].set_ylim(0, 5)\n",
    "\n",
    "        # axs[i, j].set_title(f'Plot {i*3 + j + 1}')\n",
    "\n",
    "# Ajouter les légendes pour les lignes et les colonnes\n",
    "for i, label in enumerate(row_labels):\n",
    "    axs[i, 0].annotate(label, xy=(-0.3, 0.5), xycoords='axes fraction',\n",
    "                       va='center', ha='right', fontsize=12, rotation=90)\n",
    "\n",
    "for j, label in enumerate(col_labels):\n",
    "    axs[0, j].annotate(label, xy=(0.5, 1.1), xycoords='axes fraction',\n",
    "                       va='bottom', ha='center', fontsize=12)\n",
    "\n",
    "# Ajuster les espaces entre les plots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Afficher la figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d8d3dd-5a43-411b-9cf3-48d3a59e3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = plot_xy(steps, corr_models_rv, \n",
    "             xlabel='epoch', ylabel='brain correlation', \n",
    "             logx=True)\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'llms_params_corr_rv.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7e3055-ba7f-42dc-8de5-39b0a8f3cba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nocorr_models_rv = np.array([np.mean(corr_voxels[16808]) for corr_voxels in corr_voxels_models])\n",
    "\n",
    "fh = plot_xy(steps, nocorr_models_rv, \n",
    "             xlabel='epoch', ylabel='brain correlation', \n",
    "             logx=True)\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'llms_params_corr_rv.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e402abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nocorr_models_rv = np.array([np.mean(corr_voxels[0]) for corr_voxels in corr_voxels_models])\n",
    "\n",
    "fh = plot_xy(steps, nocorr_models_rv, \n",
    "             xlabel='epoch', ylabel='brain correlation', \n",
    "             logx=True)\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'llms_params_corr_rv.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de47e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nocorr_models_rv = np.array(corr_layers_models[-1])\n",
    "\n",
    "fh = plot_xy(range(len(nocorr_models_rv)), nocorr_models_rv, \n",
    "             xlabel='LLM layer', ylabel='brain correlation')\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'llms_params_corr_rv.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1207f78-7367-49df-9a07-3c69b88e1455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae04a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Créez un widget slider\n",
    "step_slider = widgets.IntSlider(min=0, max=9, step=1, description='Step Index')\n",
    "\n",
    "# Fonction pour afficher une image donnée par l'indice du slider\n",
    "def show_image(step_idx):\n",
    "    display(Image(filename=f'lop_{step_idx}.png'))\n",
    "\n",
    "# Connectez le slider à la fonction de plot\n",
    "interactive_plot = widgets.interactive(show_image, step_idx=step_slider)\n",
    "display(interactive_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37f91a8-e5b9-4413-9d12-75bd7ab3d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ baselines ################################\n",
    "\n",
    "# look at random embeddings\n",
    "corr_random_emb_300 = []\n",
    "for seed in range(1,11):\n",
    "    model_name ='random_embedding_300d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr_random_emb_300.append(corr)\n",
    "corr_random_emb_300 = np.mean(corr_random_emb_300, axis=0)\n",
    "\n",
    "corr_random_emb_1024 = []\n",
    "for seed in range(1,11):\n",
    "    model_name ='random_embedding_1024d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr_random_emb_1024.append(corr)\n",
    "corr_random_emb_1024 = np.mean(corr_random_emb_1024, axis=0)\n",
    "\n",
    "corr2_random_emb_1024 = []\n",
    "for seed in range(11,12):\n",
    "    model_name ='random_embedding_1024d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "        imgtmp = nifti_masker.inverse_transform(corr)\n",
    "        plotting.plot_img_on_surf(imgtmp,\n",
    "                                  surf_mesh='fsaverage5',\n",
    "                                  views=['lateral'],\n",
    "                                  hemispheres=['left', 'right'],\n",
    "                                  vmin=-0, vmax=0.3,\n",
    "                                  cmap='Spectral_r',\n",
    "                                  symmetric_cbar=False,\n",
    "                                  cbar_tick_format='%.2f',\n",
    "                                  colorbar=True,\n",
    "                                  title=\"exemple de corrélations entre le cerveau et un layer\")\n",
    "        plt.show()\n",
    "    corr2_random_emb_1024.append(corr)\n",
    "corr2_random_emb_1024 = np.mean(corr2_random_emb_1024, axis=0)\n",
    "imgtmp = nifti_masker.inverse_transform(corr2_random_emb_1024)\n",
    "plotting.plot_img_on_surf(imgtmp,\n",
    "                            surf_mesh='fsaverage5',\n",
    "                            views=['lateral'],\n",
    "                            hemispheres=['left', 'right'],\n",
    "                            vmin=-0.3, vmax=0.3,\n",
    "                            cmap='Spectral_r',\n",
    "                            symmetric_cbar=False,\n",
    "                            cbar_tick_format='%.2f',\n",
    "                            colorbar=True,\n",
    "                            title=\"x\")\n",
    "plt.show()\n",
    "\n",
    "corr_random_vec_1024 = []\n",
    "for seed in range(1,9):\n",
    "    model_name ='random_vector_1024d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "        corr_voxels = np.array(corr)\n",
    "    corr_random_vec_1024.append(corr)\n",
    "corr_random_vec_1024 = np.mean(corr_random_vec_1024, axis=0)\n",
    "\n",
    "\n",
    "corr_lograndom_vec_1024 = []\n",
    "for seed in range(10,18):\n",
    "    model_name ='random_vector_1024d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr_lograndom_vec_1024.append(corr)\n",
    "corr_lograndom_vec_1024 = np.mean(corr_lograndom_vec_1024, axis=0)\n",
    "\n",
    "corr_lograndom_vec_300 = []\n",
    "for seed in range(100,110):\n",
    "    model_name ='random_vector_300d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr_lograndom_vec_300.append(corr)\n",
    "corr_lograndom_vec_300 = np.mean(corr_lograndom_vec_300, axis=0)\n",
    "\n",
    "corr_exprandom_vec_1024 = []\n",
    "for seed in range(30,40):\n",
    "    model_name ='random_vector_1024d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr_exprandom_vec_1024.append(corr)\n",
    "    print(corr_exprandom_vec_1024)\n",
    "corr_exprandom_vec_1024 = np.mean(corr_exprandom_vec_1024, axis=0)\n",
    "\n",
    "corr_cauchyrandom_vec_1024 = []\n",
    "for seed in range(40,50):\n",
    "    model_name ='random_vector_1024d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr_cauchyrandom_vec_1024.append(corr)\n",
    "corr_cauchyrandom_vec_1024 = np.mean(corr_cauchyrandom_vec_1024, axis=0)\n",
    "\n",
    "corr_georandom_vec_1024 = []\n",
    "for seed in range(50,60):\n",
    "    model_name ='random_vector_1024d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr_georandom_vec_1024.append(corr)\n",
    "corr_georandom_vec_1024 = np.mean(corr_georandom_vec_1024, axis=0)\n",
    "\n",
    "corr_lograndom_emb_1024 = []\n",
    "for seed in range(20,28):\n",
    "    model_name ='random_embedding_1024d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr_lograndom_emb_1024.append(corr)\n",
    "corr_lograndom_emb_1024 = np.mean(corr_lograndom_emb_1024, axis=0)\n",
    "\n",
    "corr_exprandom_emb_1024 = []\n",
    "for seed in range(30,39):\n",
    "    model_name ='random_embedding_1024d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr_exprandom_emb_1024.append(corr)\n",
    "corr_exprandom_emb_1024 = np.mean(corr_exprandom_emb_1024, axis=0)\n",
    "\n",
    "corr_cauchyrandom_emb_1024 = []\n",
    "for seed in range(40,49):\n",
    "    model_name ='random_embedding_1024d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr_cauchyrandom_emb_1024.append(corr)\n",
    "corr_cauchyrandom_emb_1024 = np.mean(corr_cauchyrandom_emb_1024, axis=0)\n",
    "\n",
    "corr_georandom_emb_1024 = []\n",
    "for seed in range(50,59):\n",
    "    model_name ='random_embedding_1024d_seed{}'.format(seed)\n",
    "    filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "    with open(filename, 'rb') as f:\n",
    "        corr = joblib.load(f)\n",
    "    corr_georandom_emb_1024.append(corr)\n",
    "corr_georandom_emb_1024 = np.mean(corr_georandom_emb_1024, axis=0)\n",
    "\n",
    "model_name ='onehot_emb'\n",
    "filename = os.path.join(glm_folder, 'onehot_emb_layer-0_corr.gz')\n",
    "with open(filename, 'rb') as f:\n",
    "    corr_onehot = joblib.load(f)\n",
    "\n",
    "model_name ='onehot_emb2'\n",
    "filename = os.path.join(glm_folder, 'onehot_emb2_layer-0_corr.gz')\n",
    "with open(filename, 'rb') as f:\n",
    "    corr_onehot2 = joblib.load(f)\n",
    "print(corr_onehot2, min(corr_onehot2))\n",
    "\n",
    "\n",
    "model_name ='onehotlongphoneme'\n",
    "filename = os.path.join(glm_folder, 'onehotlongphoneme_layer-0_corr.gz')\n",
    "with open(filename, 'rb') as f:\n",
    "    onehotlongphoneme = joblib.load(f)\n",
    "\n",
    "model_name ='onehotphoneme_emb'\n",
    "filename = os.path.join(glm_folder, 'onehotphoneme_emb_layer-0_corr.gz')\n",
    "with open(filename, 'rb') as f:\n",
    "    corr_onehotphoneme = joblib.load(f)\n",
    "\n",
    "model_name ='onehotphoneme_emb2'\n",
    "filename = os.path.join(glm_folder, 'onehotphoneme_emb2_layer-0_corr.gz')\n",
    "with open(filename, 'rb') as f:\n",
    "    corr_onehotphoneme2 = joblib.load(f)\n",
    "\n",
    "model_name ='onehotphoneme_embnoalpha'\n",
    "filename = os.path.join(glm_folder, 'onehotphoneme_embnoalpha_layer-0_corr.gz')\n",
    "with open(filename, 'rb') as f:\n",
    "    corr_onehotphonemenoalpha = joblib.load(f)\n",
    "\n",
    "# onehot_embnoalpha\n",
    "model_name ='onehot_embnoalpha'\n",
    "filename = os.path.join(glm_folder, 'onehot_embnoalpha_layer-0_corr.gz')\n",
    "with open(filename, 'rb') as f:\n",
    "    onehot_embnoalpha = joblib.load(f)\n",
    "# GloVe\n",
    "model_name ='glove'\n",
    "filename = os.path.join(glm_folder, '{}_layer-{}_corr.gz'.format(model_name, 0))\n",
    "with open(filename, 'rb') as f:\n",
    "    corr_glove = joblib.load(f)\n",
    "\n",
    "model_name ='randomembjump'\n",
    "filename = os.path.join(glm_folder, 'randomembjump_layer-0_corr.gz')\n",
    "with open(filename, 'rb') as f:\n",
    "    randomembjump = joblib.load(f)\n",
    "\n",
    "    \n",
    "model_name ='on est là'\n",
    "filename = os.path.join(glm_folder, 'on est là_layer-0_corr.gz')\n",
    "with open(filename, 'rb') as f:\n",
    "    autre = joblib.load(f)\n",
    "\n",
    "model_name ='on est là2'\n",
    "filename = os.path.join(glm_folder, 'on est là2_layer-0_corr.gz')\n",
    "with open(filename, 'rb') as f:\n",
    "    autre2 = joblib.load(f)\n",
    "\n",
    "model_name ='randomtestinterceptembjump'\n",
    "filename = os.path.join(glm_folder, 'testintercept10_layer-0_corr.gz')\n",
    "with open(filename, 'rb') as f:\n",
    "    testintercept = joblib.load(f)\n",
    "\n",
    "\n",
    "model_name ='randomtestinterceptembjump'\n",
    "filename = os.path.join(glm_folder, 'autretestintercept10_layer-0_corr.gz')\n",
    "with open(filename, 'rb') as f:\n",
    "    testinterceptautre = joblib.load(f)\n",
    "\n",
    "print(np.mean(corr_random_emb_1024[is_voxel_reliable]))\n",
    "print(np.var(corr_random_emb_1024[is_voxel_reliable]))\n",
    "is_not_reliable = [False if i else True for i in is_voxel_reliable]\n",
    "print(np.mean(corr_random_emb_1024[is_not_reliable]))\n",
    "print(np.var(corr_random_emb_1024[is_not_reliable]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95568080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "np.random.seed(0)\n",
    "print(is_voxel_reliable)\n",
    "data = [corr_random_emb_1024[is_voxel_reliable]]\n",
    "print(np.shape(data))\n",
    "# Création des traces pour chaque distribution\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, dist in enumerate(data):\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=dist,\n",
    "            name=f'Time {i}',\n",
    "            visible=False,  # Masquer toutes les traces sauf la première\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Rendre la première trace visible\n",
    "fig.data[0].visible = True\n",
    "\n",
    "# Création des boutons pour le slider\n",
    "gsteps = []\n",
    "for i in range(len(data)):\n",
    "    gstep = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(data)},\n",
    "              {\"title\": f\"Distribution at Time {i}\"}],\n",
    "    )\n",
    "    gstep[\"args\"][0][\"visible\"][i] = True  # Rendre la trace actuelle visible\n",
    "    gsteps.append(gstep)\n",
    "\n",
    "sliders = [dict(\n",
    "    active=0,\n",
    "    currentvalue={\"prefix\": \"Time: \"},\n",
    "    pad={\"t\": 50},\n",
    "    steps=gsteps\n",
    ")]\n",
    "\n",
    "fig.update_layout(\n",
    "    sliders=sliders,\n",
    "    title=\"Evolution of Distribution Over Time\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c1afa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "np.random.seed(0)\n",
    "print(is_voxel_reliable)\n",
    "data = [corr_random_emb_1024[is_not_reliable]]\n",
    "print(np.shape(data))\n",
    "# Création des traces pour chaque distribution\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, dist in enumerate(data):\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=dist,\n",
    "            name=f'Time {i}',\n",
    "            visible=False,  # Masquer toutes les traces sauf la première\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Rendre la première trace visible\n",
    "fig.data[0].visible = True\n",
    "\n",
    "# Création des boutons pour le slider\n",
    "gsteps = []\n",
    "for i in range(len(data)):\n",
    "    gstep = dict(\n",
    "        method=\"update\",\n",
    "        args=[{\"visible\": [False] * len(data)},\n",
    "              {\"title\": f\"Distribution at Time {i}\"}],\n",
    "    )\n",
    "    gstep[\"args\"][0][\"visible\"][i] = True  # Rendre la trace actuelle visible\n",
    "    gsteps.append(gstep)\n",
    "\n",
    "sliders = [dict(\n",
    "    active=0,\n",
    "    currentvalue={\"prefix\": \"Time: \"},\n",
    "    pad={\"t\": 50},\n",
    "    steps=gsteps\n",
    ")]\n",
    "\n",
    "fig.update_layout(\n",
    "    sliders=sliders,\n",
    "    title=\"Evolution of Distribution Over Time\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83db7a45-eed2-4cab-bfa5-60e6e69c2578",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_baseline = sns.color_palette('crest', n_colors=15)[::5]\n",
    "\n",
    "class MyLegendHandler(HandlerBase):\n",
    "    def create_artists(self, legend, orig_handle,\n",
    "                       x0, y0, width, height, fontsize, trans):\n",
    "        lines = []\n",
    "        n_models = len(color_models[::8])\n",
    "        for i, color in enumerate(color_models[::8]):\n",
    "             lines.append(plt.Line2D([x0,y0+width], \n",
    "                               [i/n_models*height,i/n_models*height], \n",
    "                               color=color))\n",
    "        return lines\n",
    "\n",
    "fh = plt.figure(figsize=(8, 4))\n",
    "ax = plt.subplot(111)\n",
    "sns.kdeplot(corr_random_vec_1024, c=color_baseline[0], lw=2, alpha=0.9, cut=0., ax=ax);\n",
    "#ax.set_yticks([])\n",
    "ax.set_yticklabels([])\n",
    "ax.tick_params(axis='y', length=0)\n",
    "plt.xlabel('brain correlation')\n",
    "plt.ylabel('normalized density')\n",
    "ax = plt.twinx()\n",
    "sns.kdeplot(corr_random_vec_1024, c=color_baseline[0], ls='--', lw=2, alpha=0.9, cut=0.);\n",
    "ax.grid(None)\n",
    "ax.axis('off')\n",
    "ax = plt.twinx()\n",
    "sns.kdeplot(corr_random_emb_300, c=color_baseline[1], lw=2, alpha=0.9, cut=0.);\n",
    "ax.grid(None)\n",
    "ax.axis('off')\n",
    "ax = plt.twinx()\n",
    "sns.kdeplot(corr_random_emb_1024, c=color_baseline[1], ls='--', lw=2, alpha=0.9, cut=0.);\n",
    "ax.grid(None)\n",
    "ax.axis('off')\n",
    "ax = plt.twinx()\n",
    "sns.kdeplot(corr_glove, c=color_baseline[2], lw=2, alpha=0.9, cut=0.);\n",
    "ax.grid(None)\n",
    "ax.axis('off')\n",
    "for corr_voxels, color in zip(corr_voxels_models, color_models):\n",
    "    ax = plt.twinx()\n",
    "    sns.kdeplot(corr_voxels, color=color, lw=1.5, alpha=0.6, cut=0.);\n",
    "    ax.grid(None)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.plot([0], c=color_baseline[0], lw=2, label='random vectors 1024d')\n",
    "plt.plot([0], c=color_baseline[0], lw=2, ls='--', label='random vectors 1024d')\n",
    "plt.plot([0], c=color_baseline[1], lw=2, label='random embeddings 300d')\n",
    "plt.plot([0], c=color_baseline[1], lw=2, ls='--', label='random embeddings 1024d')\n",
    "plt.plot([0], c=color_baseline[2], lw=2, label='GloVe')\n",
    "\n",
    "hllm, = plt.plot([0], label='28 large language models')\n",
    "\n",
    "ax.tick_params(axis='y', labelleft='off')\n",
    "\n",
    "plt.legend(handler_map={hllm: MyLegendHandler()}, bbox_to_anchor=(1.01,1), loc='upper left')\n",
    "\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'distribution_correlation_models_baselines.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3209a134-c6ad-4893-8188-6ad0dcd77ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = plt.figure(figsize=(8, 4))\n",
    "ax = plt.subplot(111)\n",
    "sns.kdeplot(corr_random_vec_1024[is_voxel_reliable], c=color_baseline[0], lw=2, alpha=0.9, cut=0., ax=ax);\n",
    "ax.set_yticklabels([])\n",
    "ax.tick_params(axis='y', length=0)\n",
    "plt.xlabel('brain correlation')\n",
    "plt.ylabel('normalized density')\n",
    "ax = plt.twinx()\n",
    "sns.kdeplot(corr_random_vec_1024[is_voxel_reliable], c=color_baseline[0], ls='--', lw=2, alpha=0.9, cut=0., ax=ax);\n",
    "ax.grid(None)\n",
    "ax.axis('off')\n",
    "ax = plt.twinx()\n",
    "sns.kdeplot(corr_random_emb_300[is_voxel_reliable], c=color_baseline[1], lw=2, alpha=0.9, cut=0., ax=ax);\n",
    "ax.grid(None)\n",
    "ax.axis('off')\n",
    "ax = plt.twinx()\n",
    "sns.kdeplot(corr_random_emb_1024[is_voxel_reliable], c=color_baseline[1], ls='--', lw=2, alpha=0.9, cut=0., ax=ax);\n",
    "ax.grid(None)\n",
    "ax.axis('off')\n",
    "ax = plt.twinx()\n",
    "sns.kdeplot(corr_glove[is_voxel_reliable], c=color_baseline[2], lw=2, alpha=0.9, cut=0., ax=ax);\n",
    "ax.grid(None)\n",
    "ax.axis('off')\n",
    "for corr_voxels, color in zip(corr_voxels_models, color_models):\n",
    "    ax = plt.twinx()\n",
    "    sns.kdeplot(corr_voxels[is_voxel_reliable], color=color, lw=1.5, alpha=0.6, cut=0., ax=ax);\n",
    "    ax.grid(None)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.plot([0], c=color_baseline[0], lw=2, label='random vectors 300d')\n",
    "plt.plot([0], c=color_baseline[0], lw=2, ls='--', label='random vectors 1024d')\n",
    "plt.plot([0], c=color_baseline[1], lw=2, label='random embeddings 300d')\n",
    "plt.plot([0], c=color_baseline[1], lw=2, ls='--', label='random embeddings 1024d')\n",
    "plt.plot([0], c=color_baseline[2], lw=2, label='GloVe')\n",
    "\n",
    "hllm, = plt.plot([0], label='28 large language models')\n",
    "\n",
    "ax.tick_params(axis='y', labelleft='off')\n",
    "\n",
    "plt.legend(handler_map={hllm: MyLegendHandler()}, bbox_to_anchor=(1.01,1), loc='upper left')\n",
    "\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'distribution_correlation_models_baselines_rv.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bdcbde-b6a2-45c1-af59-6a3cb4034b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## best model ########\n",
    "idx_best_model = np.argmax(corr_models_rv)\n",
    "\n",
    "print(model_names[idx_best_model])\n",
    "corr_voxels = corr_voxels_models[idx_best_model]\n",
    "\n",
    "imgtmp = nifti_masker.inverse_transform(corr_voxels - corr_random_emb_1024)\n",
    "\n",
    "vmax = np.max(corr_voxels - corr_random_emb_1024)\n",
    "\n",
    "fh, axes = plotting.plot_img_on_surf(imgtmp,\n",
    "                                     surf_mesh='fsaverage5',\n",
    "                                     views=['lateral'],\n",
    "                                     hemispheres=['left', 'right'],\n",
    "                                     vmin=0., vmax=vmax,\n",
    "                                     cmap='Spectral_r',\n",
    "                                     symmetric_cbar=False,\n",
    "                                     cbar_tick_format='%.2f',\n",
    "                                     colorbar=True,\n",
    "                                     title=str(model_names[idx_best_model]))\n",
    "for ax in axes[0:2]:\n",
    "    ax.set_box_aspect(None, zoom=1.45)\n",
    "fh.set_size_inches(7, 4.3)\n",
    "plotting.show()\n",
    "\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'brain_best_over_random_emb.pdf'), bbox_inches='tight', \n",
    "               transparent=True, facecolor=(1,1,1,0))\n",
    "    \n",
    "######## worst model ########\n",
    "idx_worst_model = np.argmin(corr_models_rv)\n",
    "\n",
    "print(model_names[idx_worst_model])\n",
    "\n",
    "corr_voxels = corr_voxels_models[idx_worst_model]\n",
    "\n",
    "imgtmp = nifti_masker.inverse_transform(corr_voxels)\n",
    "\n",
    "fh, axes = plotting.plot_img_on_surf(imgtmp,\n",
    "                                     surf_mesh='fsaverage5',\n",
    "                                     views=['lateral'],\n",
    "                                     hemispheres=['left', 'right'],\n",
    "                                     vmin=0., vmax=vmax,\n",
    "                                     cmap='Spectral_r',\n",
    "                                     symmetric_cbar=False,\n",
    "                                     cbar_tick_format='%.2f',\n",
    "                                     colorbar=True,\n",
    "                                     title=str(model_names[idx_worst_model]))\n",
    "for ax in axes[0:2]:\n",
    "    ax.set_box_aspect(None, zoom=1.45)\n",
    "fh.set_size_inches(7, 4.3)\n",
    "plotting.show()\n",
    "\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'brain_worst_over_random_emb.pdf'), bbox_inches='tight', \n",
    "               transparent=True, facecolor=(1,1,1,0))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b2825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from nilearn import plotting\n",
    "\n",
    "# Les données doivent être préparées à l'avance\n",
    "# steps = [1_000, *range(10_000, 140_000, 10_000), 143000]\n",
    "# corr_models_rv = [...]\n",
    "vmax = np.max(np.max(corr_voxels_models, axis=0)-corr_glove)\n",
    "for step_idx in range(len(steps)):\n",
    "    idx_best_model = step_idx\n",
    "    print(f'Generating image for step {steps[step_idx]}')\n",
    "    \n",
    "    corr_voxels = corr_voxels_models[idx_best_model]\n",
    "    imgtmp = nifti_masker.inverse_transform(corr_voxels-corr_glove)\n",
    "    \n",
    "    # Enregistrez l'image directement sans utiliser axes\n",
    "    temp_filename = f'temp12b_{step_idx}.png'\n",
    "    plotting.plot_img_on_surf(imgtmp,\n",
    "                              surf_mesh='fsaverage5',\n",
    "                              views=['lateral'],\n",
    "                              hemispheres=['left', 'right'],\n",
    "                              vmin=0., vmax=vmax,\n",
    "                              cmap='Spectral_r',\n",
    "                              symmetric_cbar=False,\n",
    "                              cbar_tick_format='%.2f',\n",
    "                              colorbar=True,\n",
    "                              title=str(model_names[idx_best_model]))\n",
    "    \n",
    "    plt.savefig(temp_filename)\n",
    "    plt.close()\n",
    "\n",
    "# Optionnel : sauvegardez toutes les images sous forme de GIF pour vérification\n",
    "images = [imageio.imread(f'temp12b_{i}.png') for i in range(len(steps))]\n",
    "imageio.mimsave('brain_correlations.gif', images, duration=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df925a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Créez un widget slider\n",
    "step_slider = widgets.IntSlider(min=0, max=len(steps)-1, step=1, description='Step Index')\n",
    "\n",
    "# Fonction pour afficher une image donnée par l'indice du slider\n",
    "def show_image(step_idx):\n",
    "    display(Image(filename=f'temp12b_{step_idx}.png'))\n",
    "\n",
    "# Connectez le slider à la fonction de plot\n",
    "interactive_plot = widgets.interactive(show_image, step_idx=step_slider)\n",
    "display(interactive_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4e06f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from nilearn import plotting\n",
    "\n",
    "# Les données doivent être préparées à l'avance\n",
    "# steps = [1_000, *range(10_000, 140_000, 10_000), 143000]\n",
    "# corr_models_rv = [...]\n",
    "vmax = np.max(np.max(corr_voxels_models, axis=0))\n",
    "for step_idx in range(len(steps)):\n",
    "    idx_best_model = step_idx\n",
    "    print(f'Generating image for step {steps[step_idx]}')\n",
    "    \n",
    "    corr_voxels = corr_voxels_models[idx_best_model]\n",
    "    imgtmp = nifti_masker.inverse_transform(corr_voxels)\n",
    "    \n",
    "    # Enregistrez l'image directement sans utiliser axes\n",
    "    temp_filename = f'tempnocorr_{step_idx}.png'\n",
    "    plotting.plot_img_on_surf(imgtmp,\n",
    "                              surf_mesh='fsaverage5',\n",
    "                              views=['lateral'],\n",
    "                              hemispheres=['left', 'right'],\n",
    "                              vmin=0., vmax=vmax,\n",
    "                              cmap='Spectral_r',\n",
    "                              symmetric_cbar=False,\n",
    "                              cbar_tick_format='%.2f',\n",
    "                              colorbar=True,\n",
    "                              title=str(model_names[idx_best_model]))\n",
    "    \n",
    "    plt.savefig(temp_filename)\n",
    "    plt.close()\n",
    "\n",
    "# Optionnel : sauvegardez toutes les images sous forme de GIF pour vérification\n",
    "images = [imageio.imread(f'tempnocorr_{i}.png') for i in range(len(steps))]\n",
    "imageio.mimsave('brain_correlations_nocorr.gif', images, duration=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3789d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Créez un widget slider\n",
    "step_slider = widgets.IntSlider(min=0, max=len(steps)-1, step=1, description='Step Index')\n",
    "\n",
    "# Fonction pour afficher une image donnée par l'indice du slider\n",
    "def show_image(step_idx):\n",
    "    display(Image(filename=f'tempnocorr_{step_idx}.png'))\n",
    "\n",
    "# Connectez le slider à la fonction de plot\n",
    "interactive_plot = widgets.interactive(show_image, step_idx=step_slider)\n",
    "display(interactive_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1af3f3-0cb4-4ff5-bad1-0eed8baab004",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ L/R Asymmetries ################################\n",
    "# whole brain\n",
    "\n",
    "#l r asym in baselines\n",
    "for corr_voxels in [corr_random_emb_300, corr_random_emb_1024, corr2_random_emb_1024, corr_lograndom_emb_1024,\n",
    "                    corr_glove, corr_random_vec_1024, corr_lograndom_vec_1024]:\n",
    "    print((corr_voxels[:n_voxels//2].mean() - corr_voxels[n_voxels//2:].mean()) / np.mean(corr_voxels))\n",
    "    print((corr_voxels[:n_voxels//2].mean() - corr_voxels[n_voxels//2:].mean()))\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec99f2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from nilearn import plotting\n",
    "\n",
    "\n",
    "vmax = np.max(np.max(corr_voxels_models, axis=0)-corr_random_emb_1024)\n",
    "for i, random_emb_corr in enumerate([corr_random_emb_300, corr_random_emb_1024, corr2_random_emb_1024,\n",
    "                                     corr_lograndom_emb_1024, corr_random_vec_1024, corr_lograndom_vec_1024,\n",
    "                                     corr_glove, corr_onehotphoneme]):\n",
    "    print(\"generation img no correction\")\n",
    "    corr_voxels = random_emb_corr\n",
    "    imgtmp = nifti_masker.inverse_transform(corr_voxels)\n",
    "    \n",
    "    # Enregistrez l'image directement sans utiliser axes\n",
    "    temp_filename = f'penocor_{i}.png'\n",
    "    plotting.plot_img_on_surf(imgtmp,\n",
    "                              surf_mesh='fsaverage5',\n",
    "                              views=['lateral'],\n",
    "                              hemispheres=['left', 'right'],\n",
    "                              vmin=0., vmax=vmax,\n",
    "                              cmap='Spectral_r',\n",
    "                              symmetric_cbar=False,\n",
    "                              cbar_tick_format='%.2f',\n",
    "                              colorbar=True,\n",
    "                              title=str(model_names[idx_best_model]))\n",
    "    \n",
    "    plt.savefig(temp_filename)\n",
    "    plt.close()\n",
    "\n",
    "# Optionnel : sauvegardez toutes les images sous forme de GIF pour vérification\n",
    "images = [imageio.imread(f'penocor_{i}.png') for i in range(6)]\n",
    "imageio.mimsave('tempbruit_.gif', images, duration=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc655f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Créez un widget slider\n",
    "step_slider = widgets.IntSlider(min=0, max=6, step=1, description='Step Index')\n",
    "\n",
    "# Fonction pour afficher une image donnée par l'indice du slider\n",
    "def show_image(step_idx):\n",
    "    display(Image(filename=f'penocor_{step_idx}.png'))\n",
    "\n",
    "# Connectez le slider à la fonction de plot\n",
    "interactive_plot = widgets.interactive(show_image, step_idx=step_slider)\n",
    "display(interactive_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058023b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_var_name(var):\n",
    "    for name, value in locals().items():\n",
    "        if value is var:\n",
    "            return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac89acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from nilearn import plotting\n",
    "\n",
    "vmin=0\n",
    "vmax = np.max(np.max(corr_voxels_models, axis=0)-corr_random_emb_1024)\n",
    "noms = ['corr_random_emb_300', 'corr_random_emb_1024', 'corr2_random_emb_1024',\n",
    "        'corr_lograndom_emb_1024', 'corr_exprandom_emb_1024', 'corr_cauchyrandom_emb_1024',\n",
    "        'corr_georandom_emb_1024','corr_random_vec_1024', 'corr_lograndom_vec_300', 'corr_lograndom_vec_1024',\n",
    "        'corr_exprandom_vec_1024', 'corr_georandom_vec_1024', 'corr_cauchyrandom_vec_1024',\n",
    "        'corr_onehot', 'corr_onehot2', 'onehotlongphoneme', 'corr_onehotphoneme', 'corr_onehotphoneme2', 'corr_onehotphonemenoalpha',\n",
    "        'onehot_embnoalpha', 'corr_glove', 'randomembjump', 'autre', 'autre2', 'kurtosis', 'skewness', 'corr_random_emb_1024', 'corr_lograndom_vec_1024', 'absskewness']\n",
    "models = [corr_random_emb_300, corr_random_emb_1024, corr2_random_emb_1024,\n",
    "                                     corr_lograndom_emb_1024, corr_exprandom_emb_1024,\n",
    "                                     corr_cauchyrandom_emb_1024, corr_georandom_emb_1024,\n",
    "                                     corr_random_vec_1024, corr_lograndom_vec_300, corr_lograndom_vec_1024,\n",
    "                                     corr_exprandom_vec_1024, corr_georandom_vec_1024, corr_cauchyrandom_vec_1024,\n",
    "                                     corr_onehot, corr_onehot2, onehotlongphoneme, corr_onehotphoneme, corr_onehotphoneme2, corr_onehotphonemenoalpha,\n",
    "                                     onehot_embnoalpha, corr_glove, randomembjump, autre, autre2, testinterceptautre, testintercept, corr_random_emb_1024,\n",
    "                                     corr_lograndom_vec_1024, np.abs(testintercept)]\n",
    "print(len(models), len(noms))\n",
    "for i, random_emb_corr in enumerate(models):\n",
    "    print(\"generation img no correction\")\n",
    "    corr_voxels = np.array(random_emb_corr)\n",
    "    imgtmp = nifti_masker.inverse_transform(corr_voxels)\n",
    "    \n",
    "    # Enregistrez l'image directement sans utiliser axes\n",
    "    temp_filename = f'tempbruit_{i}.png'\n",
    "    if i == 21:\n",
    "        vmax=0.8\n",
    "        vmin=0.3\n",
    "    if i == 22:\n",
    "        vmax=0.04\n",
    "        vmin=-0.3\n",
    "    if i == 23:\n",
    "        vmax=0.82\n",
    "        vmin=0.2\n",
    "    if i == 24:\n",
    "        vmax=0.5\n",
    "        vmin=-0.5\n",
    "    if i == 26:\n",
    "        vmax=np.max(random_emb_corr)\n",
    "        vmin=0\n",
    "    plotting.plot_img_on_surf(imgtmp,\n",
    "                              surf_mesh='fsaverage5',\n",
    "                              views=['lateral'],\n",
    "                              hemispheres=['left', 'right'],\n",
    "                              vmin=vmin, vmax=vmax,\n",
    "                              cmap='Spectral_r',\n",
    "                              symmetric_cbar=False,\n",
    "                              cbar_tick_format='%.2f',\n",
    "                              colorbar=True,\n",
    "                              title=noms[i])\n",
    "    \n",
    "    plt.savefig(temp_filename)\n",
    "    plt.close()\n",
    "\n",
    "# Optionnel : sauvegardez toutes les images sous forme de GIF pour vérification\n",
    "images = [imageio.imread(f'tempbruit_{i}.png') for i in range(12)]\n",
    "imageio.mimsave('tempbruit_.gif', images, duration=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea57536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Créez un widget slider\n",
    "step_slider = widgets.IntSlider(min=0, max=28, step=1, description='Step Index')\n",
    "\n",
    "# Fonction pour afficher une image donnée par l'indice du slider\n",
    "def show_image(step_idx):\n",
    "    display(Image(filename=f'tempbruit_{step_idx}.png'))\n",
    "\n",
    "# Connectez le slider à la fonction de plot\n",
    "interactive_plot = widgets.interactive(show_image, step_idx=step_slider)\n",
    "display(interactive_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ebfa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Supposons que vos données sont déjà chargées dans les variables correspondantes\n",
    "# corr_random_emb_300, corr_random_emb_1024, etc.\n",
    "\n",
    "# Créez une liste de toutes les corrélations\n",
    "all_correlations = [corr_random_vec_1024, corr_lograndom_vec_1024,\n",
    "                    corr_exprandom_vec_1024, corr_georandom_vec_1024, corr_cauchyrandom_vec_1024]\n",
    "\n",
    "# Convertissez la liste en un tableau numpy\n",
    "all_correlations = np.array(all_correlations)\n",
    "\n",
    "# Trouvez l'indice du bruit avec la corrélation maximale pour chaque voxel\n",
    "max_corr_indices = np.argmax(all_correlations, axis=0)\n",
    "max_corr = np.max(all_correlations, axis=0)\n",
    "\n",
    "# Créez une image où chaque voxel est coloré en fonction de l'indice maximal\n",
    "imgtmp = nifti_masker.inverse_transform(max_corr_indices)\n",
    "imgtmp2 = nifti_masker.inverse_transform(max_corr)\n",
    "\n",
    "# Définissez les noms des bruits pour l'affichage\n",
    "noms = ['corr_random_vec_1024', 'corr_lograndom_vec_1024',\n",
    "        'corr_exprandom_vec_1024', 'corr_georandom_vec_1024', 'corr_cauchyrandom_vec_1024']\n",
    "\n",
    "# Créez une colormap personnalisée\n",
    "cmap = plt.get_cmap('tab20', len(noms))\n",
    "\n",
    "# Créez les couleurs pour chaque nom\n",
    "colors = cmap(np.arange(len(noms)))\n",
    "\n",
    "# Créez une légende pour les couleurs\n",
    "cmap = mcolors.ListedColormap(colors)\n",
    "bounds = np.arange(len(noms) + 1) - 0.5\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# Créez la figure et les axes pour l'affichage\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10), subplot_kw={'projection': '3d'})\n",
    "\n",
    "# Plot the first brain image\n",
    "display = plotting.plot_img_on_surf(imgtmp,\n",
    "                                    surf_mesh='fsaverage5',\n",
    "                                    views=['lateral'],\n",
    "                                    hemispheres=['left', 'right'],\n",
    "                                    vmin=-0.5, vmax=len(noms) - 0.5,\n",
    "                                    cmap=cmap,\n",
    "                                    colorbar=True,\n",
    "                                    title='Max Correlation per Voxel')\n",
    "plt.savefig('unique_plot_max_correlation.png', bbox_inches='tight')\n",
    "# Plot the second brain image\n",
    "display2 = plotting.plot_img_on_surf(imgtmp2,\n",
    "                                     surf_mesh='fsaverage5',\n",
    "                                     views=['lateral'],\n",
    "                                     hemispheres=['left', 'right'],\n",
    "                                     vmin=0., vmax=vmax,\n",
    "                                     cmap='Spectral_r',\n",
    "                                     symmetric_cbar=False,\n",
    "                                     cbar_tick_format='%.2f',\n",
    "                                     colorbar=True,\n",
    "                                     title=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb4b47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Supposons que vos données sont déjà chargées dans les variables correspondantes\n",
    "# corr_random_emb_300, corr_random_emb_1024, etc.\n",
    "\n",
    "# Créez une liste de toutes les corrélations\n",
    "all_correlations = [corr_random_emb_300, corr_random_emb_1024, corr2_random_emb_1024,\n",
    "                    corr_lograndom_emb_1024, corr_exprandom_emb_1024, corr_cauchyrandom_emb_1024,\n",
    "                    corr_georandom_emb_1024]\n",
    "\n",
    "# Convertissez la liste en un tableau numpy\n",
    "all_correlations = np.array(all_correlations)\n",
    "\n",
    "# Trouvez l'indice du bruit avec la corrélation maximale pour chaque voxel\n",
    "max_corr_indices = np.argmax(all_correlations, axis=0)\n",
    "max_corr = np.max(all_correlations, axis=0)\n",
    "\n",
    "# Créez une image où chaque voxel est coloré en fonction de l'indice maximal\n",
    "imgtmp = nifti_masker.inverse_transform(max_corr_indices)\n",
    "imgtmp2 = nifti_masker.inverse_transform(max_corr)\n",
    "\n",
    "# Définissez les noms des bruits pour l'affichage\n",
    "noms = ['corr_random_emb_300', 'corr_random_emb_1024', 'corr2_random_emb_1024',\n",
    "        'corr_lograndom_emb_1024', 'corr_exprandom_emb_1024', 'corr_cauchyrandom_emb_1024',\n",
    "        'corr_georandom_emb_1024']\n",
    "# Créez une colormap personnalisée\n",
    "cmap = plt.get_cmap('tab20', len(noms))\n",
    "\n",
    "# Créez les couleurs pour chaque nom\n",
    "colors = cmap(np.arange(len(noms)))\n",
    "\n",
    "# Créez une légende pour les couleurs\n",
    "cmap = mcolors.ListedColormap(colors)\n",
    "bounds = np.arange(len(noms) + 1) - 0.5\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# Créez la figure et les axes pour l'affichage\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10), subplot_kw={'projection': '3d'})\n",
    "\n",
    "# Plot the first brain image\n",
    "display = plotting.plot_img_on_surf(imgtmp,\n",
    "                                    surf_mesh='fsaverage5',\n",
    "                                    views=['lateral'],\n",
    "                                    hemispheres=['left', 'right'],\n",
    "                                    vmin=-0.5, vmax=len(noms) - 0.5,\n",
    "                                    cmap=cmap,\n",
    "                                    colorbar=True,\n",
    "                                    title='Max Correlation per Voxel')\n",
    "plt.savefig('unique_plot_max_correlation.png', bbox_inches='tight')\n",
    "# Plot the second brain image\n",
    "display2 = plotting.plot_img_on_surf(imgtmp2,\n",
    "                                     surf_mesh='fsaverage5',\n",
    "                                     views=['lateral'],\n",
    "                                     hemispheres=['left', 'right'],\n",
    "                                     vmin=0., vmax=vmax,\n",
    "                                     cmap='Spectral_r',\n",
    "                                     symmetric_cbar=False,\n",
    "                                     cbar_tick_format='%.2f',\n",
    "                                     colorbar=True,\n",
    "                                     title=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877b403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085ba15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noms = ['corr_random_emb_300', 'corr_random_emb_1024', 'corr2_random_emb_1024',\n",
    "        'corr_lograndom_emb_1024', 'corr_exprandom_emb_1024', 'corr_cauchyrandom_emb_1024',\n",
    "        'corr_georandom_emb_1024', 'corr_glove']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db228c8-c273-4f33-b655-da3e4ac36203",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = plt.figure(figsize=(6.4, 4.8))\n",
    "ax = plt.subplot(111)\n",
    "sns.regplot(x=steps, \n",
    "            y=np.mean(corr_l_models, axis=1),\n",
    "            logx=True, ax=ax, label='L', color=l_r_colors[0]);\n",
    "sns.regplot(x=steps, \n",
    "            y=np.mean(corr_r_models, axis=1),\n",
    "            logx=True, ax=ax, label='R', color=l_r_colors[1]);\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('steps')      \n",
    "ax.set_ylabel('brain correlation')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'l_r_all_mean.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))\n",
    "\n",
    "fh = plt.figure(figsize=(6.4, 4.8))\n",
    "ax = plt.subplot(111)\n",
    "sns.regplot(x=steps, \n",
    "            y=np.mean(corr_l_models, axis=1)-np.mean(corr_r_models, axis=1), \n",
    "            logx=True, ax=ax);\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('steps')      \n",
    "ax.set_ylabel('brain correlation: L - R')\n",
    "r, p = pearsonr(np.log(steps), (np.mean(corr_l_models, axis=1)\n",
    "                                      -np.mean(corr_r_models, axis=1)))\n",
    "fh.text(0.15, 0.85,'$r={:.2f}$\\n$p={:.1e}$'.format(r,p),\n",
    "        ha='left', va='top', fontsize=11)\n",
    "plt.show()\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'l_minus_r_all.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))\n",
    "\n",
    "fh = plt.figure(figsize=(6.4, 4.8))\n",
    "ax = plt.subplot(111)\n",
    "sns.regplot(x=steps, \n",
    "            y=np.percentile(corr_l_models, 90, axis=1),\n",
    "            logx=True, ax=ax, label='L', color=l_r_colors[0]);\n",
    "sns.regplot(x=steps, \n",
    "            y=np.percentile(corr_r_models, 90, axis=1),\n",
    "            logx=True, ax=ax, label='R', color=l_r_colors[1]);\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('steps')      \n",
    "ax.set_ylabel('brain correlation')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'l_r_all_90.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))\n",
    "\n",
    "fh = plt.figure(figsize=(6.4, 4.8))\n",
    "ax = plt.subplot(111)\n",
    "sns.regplot(x=steps, \n",
    "            y=np.percentile(corr_l_models, 90, axis=1)-np.percentile(corr_r_models, 90, axis=1),\n",
    "            logx=True, ax=ax);\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('steps')      \n",
    "ax.set_ylabel('brain correlation: L - R')\n",
    "r, p = pearsonr(np.log(steps), (np.percentile(corr_l_models, 90, axis=1)\n",
    "                                      -np.percentile(corr_r_models, 90, axis=1)))\n",
    "fh.text(0.15, 0.85,'$r={:.2f}$\\n$p={:.1e}$'.format(r,p),\n",
    "        ha='left', va='top', fontsize=11)\n",
    "plt.show()\n",
    "\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'l_minus_r_all_90.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac6b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = plt.figure(figsize=(6.4, 4.8))\n",
    "ax = plt.subplot(111)\n",
    "sns.scatterplot(x=steps, \n",
    "            y=np.mean(corr_l_models, axis=1)  - np.mean(corr2_random_emb_1024[:n_voxels//2]), ax=ax, label='L', color=l_r_colors[0]);\n",
    "sns.scatterplot(x=steps, \n",
    "            y=np.mean(corr_r_models, axis=1)  - np.mean(corr2_random_emb_1024[n_voxels//2:]), ax=ax, label='R', color=l_r_colors[1]);\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('steps')      \n",
    "ax.set_ylabel('brain correlation')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'l_r_all_mean.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))\n",
    "\n",
    "fh = plt.figure(figsize=(6.4, 4.8))\n",
    "ax = plt.subplot(111)\n",
    "sns.scatterplot(x=steps, \n",
    "            y=np.mean(corr_l_models, axis=1)-np.mean(corr_r_models, axis=1), ax=ax);\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('steps')      \n",
    "ax.set_ylabel('brain correlation: L - R')\n",
    "plt.show()\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'l_minus_r_all.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))\n",
    "\n",
    "fh = plt.figure(figsize=(6.4, 4.8))\n",
    "ax = plt.subplot(111)\n",
    "sns.scatterplot(x=steps, \n",
    "            y=np.percentile(corr_l_models, 90, axis=1), ax=ax, label='L', color=l_r_colors[0]);\n",
    "sns.scatterplot(x=steps, \n",
    "            y=np.percentile(corr_r_models, 90, axis=1), ax=ax, label='R', color=l_r_colors[1]);\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('steps')      \n",
    "ax.set_ylabel('brain correlation')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'l_r_all_90.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))\n",
    "\n",
    "fh = plt.figure(figsize=(6.4, 4.8))\n",
    "ax = plt.subplot(111)\n",
    "sns.scatterplot(x=steps, \n",
    "            y=np.percentile(corr_l_models, 90, axis=1)-np.percentile(corr_r_models, 90, axis=1), ax=ax);\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('steps')      \n",
    "ax.set_ylabel('brain correlation: L - R')\n",
    "plt.show()\n",
    "\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'l_minus_r_all_90.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a932f47-c5eb-4a7a-8750-09fc7437612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the most 25% reliable voxels\n",
    "\n",
    "#l r asym in baselines\n",
    "for corr_voxels in [corr_random_emb_300, corr_random_emb_1024,\n",
    "                    corr_glove]:\n",
    "    print(corr_voxels[:n_voxels//2][is_voxel_reliable[:n_voxels//2]].mean()\n",
    "          - corr_voxels[n_voxels//2:][is_voxel_reliable[n_voxels//2:]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0af804-bc23-466a-a38a-6d32e3720b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = plt.figure(figsize=(6.4, 4.8))\n",
    "ax = plt.subplot(111)\n",
    "sns.scatterplot(x=steps, \n",
    "            y=np.mean(corr_l_models_rv, axis=1),ax=ax, label='L', color=l_r_colors[0]);\n",
    "sns.scatterplot(x=steps, \n",
    "            y=np.mean(corr_r_models_rv, axis=1),\n",
    "             ax=ax, label='R', color=l_r_colors[1]);\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('step')      \n",
    "ax.set_ylabel('brain correlation')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'l_r_all_mean_rv.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))\n",
    "\n",
    "fh = plt.figure(figsize=(6.4, 4.8))\n",
    "ax = plt.subplot(111)\n",
    "sns.scatterplot(x=steps, \n",
    "            y=(np.mean(corr_l_models_rv, axis=1)\n",
    "               -np.mean(corr_r_models_rv, axis=1)), ax=ax);\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('step')      \n",
    "ax.set_ylabel('brain correlation: L - R')\n",
    "ax.axhline(0., ls='--', c='0.4', zorder=1);\n",
    "plt.show()\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'l_minus_r_all_rv.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812eacec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = plt.figure(figsize=(6.4, 4.8))\n",
    "ax = plt.subplot(111)\n",
    "sns.regplot(x=steps, \n",
    "            y=np.mean(corr_l_models_rv, axis=1),\n",
    "            logx=True, ax=ax, label='L', color=l_r_colors[0]);\n",
    "sns.regplot(x=steps, \n",
    "            y=np.mean(corr_r_models_rv, axis=1),\n",
    "            logx=True, ax=ax, label='R', color=l_r_colors[1]);\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('step')      \n",
    "ax.set_ylabel('brain correlation')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'l_r_all_mean_rv.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))\n",
    "\n",
    "fh = plt.figure(figsize=(6.4, 4.8))\n",
    "ax = plt.subplot(111)\n",
    "sns.regplot(x=steps, \n",
    "            y=(np.mean(corr_l_models_rv, axis=1)\n",
    "               -np.mean(corr_r_models_rv, axis=1)), \n",
    "            logx=True, ax=ax);\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('step')      \n",
    "ax.set_ylabel('brain correlation: L - R')\n",
    "r, p = pearsonr(np.log(steps), (np.mean(corr_l_models_rv, axis=1)\n",
    "                                      -np.mean(corr_r_models_rv, axis=1)))\n",
    "fh.text(0.15, 0.85,'$r={:.2f}$\\n$p={:.1e}$'.format(r,p),\n",
    "        ha='left', va='top', fontsize=11)\n",
    "plt.show()\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'l_minus_r_all_rv.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74486a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(corr_voxels_models))\n",
    "corr_voxels_models = np.array(corr_voxels_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58af90a-cc97-4185-a306-a93a1e760112",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ Slopes, voxelwise ################################\n",
    "slopes = []\n",
    "tvalues = []\n",
    "pvalues = []\n",
    "for idx_voxel in range(n_voxels):\n",
    "    y = corr_voxels_models[:, idx_voxel]\n",
    "    x = np.log(steps)\n",
    "    x = sm.add_constant(x)\n",
    "    lm = sm.OLS(y, x)\n",
    "    res = lm.fit()\n",
    "    slopes.append(res.params[1])\n",
    "    tvalues.append(res.tvalues[1])\n",
    "    pvalues.append(res.pvalues[1])\n",
    "\n",
    "slopes = np.array(slopes)\n",
    "tvalues = np.array(tvalues)\n",
    "pvalues = np.array(pvalues)\n",
    "\n",
    "vtmp = slopes.copy()\n",
    "p_thsld = 10**-7\n",
    "t_thsld = np.abs(scipy.stats.t.ppf(p_thsld/2, df=n_models-2)) #two-sided\n",
    "print(t_thsld)\n",
    "vtmp[np.abs(tvalues) < t_thsld] = np.nan\n",
    "imgtmp = nifti_masker.inverse_transform(vtmp)\n",
    "\n",
    "fh = plt.figure(figsize=(12,3))\n",
    "ax = plt.subplot(111)\n",
    "plotting.plot_glass_brain(imgtmp, threshold=0., display_mode='lyrz', cbar_tick_format='%.3f',\n",
    "                          plot_abs=False, colorbar=True, axes=ax)\n",
    "plotting.show()\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'glassbrain_slopes.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89065084-4ddc-4b5a-b878-f88a01d7dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ ROIs analysis ################################\n",
    "\n",
    "roi_names = ['TP', 'aSTS', 'pSTS', 'AG_TPJ', 'BA44', 'BA45', 'BA47']\n",
    "n_rois = len(roi_names)\n",
    "folder_mask = 'roi_masks'\n",
    "\n",
    "roi_list = [os.path.join(folder_mask, '{}.nii.gz'.format(roi_name)) for roi_name in roi_names]\n",
    "roi_list_r = [swap_img_hemispheres(roi_mask) for roi_mask in roi_list]\n",
    "rois_t = nifti_masker.transform(roi_list + roi_list_r)\n",
    "idx_rois = [np.flatnonzero(roi_t == 1.0) for roi_t in rois_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf0114a-afcf-4663-ae04-9d3aa2b32703",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = ListedColormap(l_r_colors)\n",
    "\n",
    "fh = plt.figure(figsize=(12,3))\n",
    "ax = plt.subplot(111)\n",
    "for vtmp in rois_t[:n_rois]:\n",
    "    print(np.sum(vtmp))\n",
    "    imgtmp = nifti_masker.inverse_transform(vtmp)\n",
    "    plotting.plot_glass_brain(imgtmp, display_mode='lyrz', cmap=cmap, axes=ax, alpha=0.1)\n",
    "for vtmp in rois_t[n_rois:]:\n",
    "    imgtmp = nifti_masker.inverse_transform(vtmp)\n",
    "    plotting.plot_glass_brain(imgtmp, display_mode='lyrz', cmap=cmap, axes=ax, alpha=0.1)\n",
    "plotting.plot_glass_brain(None,  display_mode='lyrz', axes=ax)\n",
    "plt.show()\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'rois_l_r.pdf'), bbox_inches='tight', transparent=True)\n",
    "    fh.savefig(os.path.join(fig_folder, 'rois_l_r.svg'), bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd36b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from nilearn import plotting\n",
    "from nilearn.image import load_img\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ROIs analysis ###############################\n",
    "\n",
    "roi_names = ['TP', 'aSTS', 'pSTS', 'AG_TPJ', 'BA44', 'BA45', 'BA47']\n",
    "n_rois = len(roi_names)\n",
    "folder_mask = 'roi_masks'\n",
    "\n",
    "roi_list = [os.path.join(folder_mask, '{}.nii.gz'.format(roi_name)) for roi_name in roi_names]\n",
    "roi_list_t = [swap_img_hemispheres(roi_mask) for roi_mask in roi_list]\n",
    "rois_t = nifti_masker.transform(roi_list_t + roi_list)\n",
    "idx_rois = [np.flatnonzero(roi == 1.0) for roi in rois_t]\n",
    "print(idx_rois)\n",
    "\n",
    "# Plotting code ###############################\n",
    "\n",
    "cmap = ListedColormap(l_r_colors)\n",
    "\n",
    "fh = plt.figure(figsize=(12, 3))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "# Plot transformed ROIs\n",
    "for vtmp in rois_t:\n",
    "    imgtmp = nifti_masker.inverse_transform(vtmp)\n",
    "    plotting.plot_glass_brain(imgtmp, display_mode='lyrz', cmap=cmap, axes=ax, alpha=0.)\n",
    "\n",
    "plotting.plot_glass_brain(None, display_mode='lyrz', axes=ax)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "if True:\n",
    "    fh.savefig(os.path.join(fig_folder, 'rois_lr.pdf'), bbox_inches='tight', transparent=True)\n",
    "    fh.savefig(os.path.join(fig_folder, 'rois_lr.svg'), bbox_inches='tight', transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5ebbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from nilearn import plotting\n",
    "from nilearn.image import load_img, math_img, new_img_like\n",
    "\n",
    "roi_names = ['TP', 'aSTS', 'pSTS', 'AG_TPJ', 'BA44', 'BA45', 'BA47']\n",
    "n_rois = len(roi_names)\n",
    "folder_mask = 'roi_masks'\n",
    "\n",
    "roi_list = [os.path.join(folder_mask, '{}.nii.gz'.format(roi_name)) for roi_name in roi_names]\n",
    "roi_list_r = [swap_img_hemispheres(roi_mask) for roi_mask in roi_list]\n",
    "rois_t = nifti_masker.transform(roi_list + roi_list_r)\n",
    "idx_rois = [np.flatnonzero(roi_t == 1.0) for roi_t in rois_t]\n",
    "print(len(idx_rois))\n",
    "print(len(roi_names))\n",
    "print(idx_rois[0])\n",
    "\n",
    "# Fonction pour créer une image symétrique\n",
    "def create_symmetric_image(img):\n",
    "    data = img.get_fdata()\n",
    "    affine = img.affine\n",
    "    # Inversion des coordonnées gauche-droite (axe x)\n",
    "    data_symmetric = np.flip(data, axis=0)\n",
    "    symmetric_img = new_img_like(img, data_symmetric, affine)\n",
    "    return symmetric_img\n",
    "\n",
    "# Charger la première image de masque pour initier la somme\n",
    "sum_img = load_img(roi_list[0])\n",
    "symmetric_img = create_symmetric_image(sum_img)\n",
    "\n",
    "# Additionner l'image originale et la symétrique\n",
    "combined_img = math_img(\"img1 + img2\", img1=sum_img, img2=symmetric_img)\n",
    "\n",
    "# Ajouter les autres images de masque et leurs symétriques\n",
    "for roi in roi_list[1:]:\n",
    "    img = load_img(roi)\n",
    "    sym_img = create_symmetric_image(img)\n",
    "    combined_img = math_img(\"img1 + img2 + img3\", img1=combined_img, img2=img, img3=sym_img)\n",
    "\n",
    "# Afficher l'image combinée sur un Glass brain\n",
    "plotting.plot_glass_brain(combined_img, title='Sum of ROIs and Symmetric Regions', display_mode='lyrz')\n",
    "\n",
    "# Affichage des graphiques\n",
    "plotting.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6020d072",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(slopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded0eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate delta_slope and delta_corr_model\n",
    "deltaslope = np.array(slopes[:n_voxels//2]) - np.array(slopes[n_voxels//2:])\n",
    "delta_corr_model = np.array(corr_voxels_models[:, :n_voxels//2]) - np.array(corr_voxels_models[:, n_voxels//2:])\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, n_rois))\n",
    "barycenter_y = np.mean(deltaslope)\n",
    "barycenter_x = np.mean(delta_corr_model[:, :], axis=1)\n",
    "# Function to plot and save graphs for each value of i\n",
    "def plot_graph(i):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(delta_corr_model[i, :], deltaslope, label='All Points')\n",
    "    for j, (idx_roi, roi_name) in enumerate(zip(idx_rois, roi_names)):\n",
    "        plt.scatter(delta_corr_model[i, idx_roi], deltaslope[idx_roi], color=colors[j], label=f'{roi_name} (i={i})')\n",
    "    plt.scatter(barycenter_x[i], barycenter_y, color='black', marker='x', s=100, label='Barycenter')\n",
    "    plt.xlabel(\"delta correlation L-R\")\n",
    "    plt.ylabel('delta slope L-R')\n",
    "    plt.title(\"delta slope vs delta correlation\")\n",
    "    plt.axhline(0, -0.5, 1, color='black')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Create an interactive slider to change the value of i\n",
    "from ipywidgets import interact\n",
    "interact(plot_graph, i=(0, 14, 1));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5887be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "# Supposons que les variables suivantes soient déjà définies\n",
    "# n_voxels, slopes, corr_voxels_models, corr_lograndom_emb_1024, idx_rois, roi_names\n",
    "\n",
    "# Calculate delta_slope and delta_corr_model\n",
    "deltaslope = np.array(slopes[:n_voxels // 2]) - np.array(slopes[n_voxels // 2:])\n",
    "delta_corr_model = np.array(corr_voxels_models[:, :n_voxels // 2]) - np.array(corr_voxels_models[:, n_voxels // 2:]) + np.array(corr_lograndom_emb_1024[n_voxels // 2:]) - np.array(corr_lograndom_emb_1024[:n_voxels // 2])\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, len(idx_rois)))\n",
    "barycenter_y = np.mean(deltaslope)\n",
    "barycenter_x = np.mean(delta_corr_model[:, :], axis=1)\n",
    "\n",
    "# Function to plot and save graphs for each value of i\n",
    "def plot_graph(i):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(delta_corr_model[i, :], deltaslope, label='All Points')\n",
    "    for j, (idx_roi, roi_name) in enumerate(zip(idx_rois, roi_names)):\n",
    "        plt.scatter(delta_corr_model[i, idx_roi], deltaslope[idx_roi], color=colors[j], label=f'{roi_name} (i={i})')\n",
    "    plt.scatter(barycenter_x[i], barycenter_y, color='black', marker='x', s=100, label='Barycenter')\n",
    "    plt.xlabel(\"delta correlation L-R\")\n",
    "    plt.ylabel('delta slope L-R')\n",
    "    plt.title(\"delta slope vs delta correlation\")\n",
    "    plt.legend()\n",
    "    plt.axhline(0, color='black')\n",
    "    plt.savefig(f\"frame_{i}.png\")\n",
    "    plt.close()\n",
    "\n",
    "# Generate and save all frames\n",
    "n_frames = 15  # Assumons que vous avez 15 images à générer\n",
    "for i in range(n_frames):\n",
    "    plot_graph(i)\n",
    "\n",
    "# Create a GIF from the saved frames\n",
    "images = []\n",
    "for i in range(n_frames):\n",
    "    filename = f\"frame_{i}.png\"\n",
    "    images.append(imageio.imread(filename))\n",
    "imageio.mimsave('delta vs slope.gif', images, duration=0.5)  # Adjust duration as needed\n",
    "\n",
    "print(\"GIF saved as 'brain_correlations.gif'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d53062b-9c9e-4e20-88f6-e009a27c48df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roi_slopes = []\n",
    "for idx_roi, roi_name in zip(idx_rois[0:n_rois], roi_names):\n",
    "    df_roi_slopes.append(pd.DataFrame({'roi':roi_name,\n",
    "                  'slope':slopes[idx_roi],\n",
    "                  'hemi':'L'}))\n",
    "for idx_roi, roi_name in zip(idx_rois[n_rois:], roi_names):\n",
    "    df_roi_slopes.append(pd.DataFrame({'roi':roi_name,\n",
    "                  'slope':slopes[idx_roi],\n",
    "                  'hemi':'R'}))\n",
    "df_roi_slopes = pd.concat(df_roi_slopes)\n",
    "\n",
    "xtickslabels_roi = []\n",
    "for roi_name in roi_names:\n",
    "    ttest = ttest_ind(df_roi_slopes[(df_roi_slopes['roi']==roi_name)&(df_roi_slopes['hemi']=='L')].slope,\n",
    "              df_roi_slopes[(df_roi_slopes['roi']==roi_name)&(df_roi_slopes['hemi']=='R')].slope)\n",
    "    print(roi_name, '\\t', \n",
    "          '{:.01e}'.format(ttest.pvalue), '\\t', pvalue2str(ttest.pvalue))\n",
    "    xtickslabels_roi.append('{}\\n({})'.format(roi_name, pvalue2str(ttest.pvalue)))\n",
    "\n",
    "fh = plt.figure(figsize=(6, 4))\n",
    "ax = plt.subplot(111)\n",
    "sns.barplot(data=df_roi_slopes, x='roi', y='slope', hue='hemi', \n",
    "            palette=l_r_colors, saturation=1.0, width=0.75, alpha=0.9,\n",
    "            ax=ax)\n",
    "plt.legend(loc='upper left')\n",
    "ax.set_xticks(ax.get_xticks())\n",
    "ax.set_xticklabels(xtickslabels_roi)\n",
    "ax.set_xlabel('')\n",
    "plt.show()\n",
    "\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'rois_slopes.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fe3437",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(corr_voxels_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe490ffc-dc95-45e9-9e56-eaa6e6166ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh, axes = plt.subplots(1, n_rois, figsize=(16,4), sharey=True)\n",
    "for i, (idx_roi_l, idx_roi_r, roi_name) in enumerate(zip(idx_rois[:n_rois], idx_rois[n_rois:], roi_names)):\n",
    "    ax = axes[i]\n",
    "    sns.scatterplot(x=steps, \n",
    "                y=np.mean(corr_voxels_models[:,idx_roi_l], axis=1),\n",
    "                 color=l_r_colors[0], ax=ax, label='L');   \n",
    "    sns.scatterplot(x=steps, \n",
    "                y=np.mean(corr_voxels_models[:,idx_roi_r], axis=1),\n",
    "                 color=l_r_colors[1], ax=ax, label='R');   \n",
    "    ax.set_xscale('log')\n",
    "\n",
    "    ax.set_title('{}'.format(roi_name))\n",
    "\n",
    "    \n",
    "axes[n_rois//2].set_xlabel('steps')      \n",
    "axes[0].set_ylabel('brain correlation')\n",
    "axes[0].legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'rois_l_r_corr.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd857504-9573-4a71-8c7e-be406c46e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_random = corr_random_emb_1024\n",
    "fh, axes = plt.subplots(1, n_rois, figsize=(16,4), sharey=True)\n",
    "for i, (idx_roi_l, idx_roi_r, roi_name) in enumerate(zip(idx_rois[:n_rois], idx_rois[n_rois:], roi_names)):\n",
    "    ax = axes[i]\n",
    "    sns.scatterplot(x=steps, \n",
    "                y=np.mean(corr_voxels_models[:,idx_roi_l] - corr_random[idx_roi_l], axis=1),\n",
    "                color=l_r_colors[0], ax=ax, label='L'); \n",
    "    sns.scatterplot(x=steps, \n",
    "                y=np.mean(corr_voxels_models[:,idx_roi_r] - corr_random[idx_roi_r], axis=1),\n",
    "                color=l_r_colors[1], ax=ax, label='R'); \n",
    "    ax.set_xscale('log')\n",
    "    ax.set_title(roi_name)\n",
    "    \n",
    "    ax.set_title('{}'.format(roi_name))\n",
    "    \n",
    "axes[n_rois//2].set_xlabel('epoch')\n",
    "axes[0].set_ylabel('brain correlation')\n",
    "axes[0].legend(loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'rois_l_r_corr_over_random.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bff327",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_easy = {'arc_easy': [(0, 1.0), (1, 1.0), (2, 0.9951060358890702), (4, 0.99836867862969), (8, 0.9951060358890702), (16, 1.0440456769983686), (32, 1.0326264274061991), (64, 1.0570962479608481), (128, 1.0505709624796085), (256, 1.030995106035889), (512, 1.0456769983686787), (1000, 1.1484502446982054), (3000, 1.7226753670473083), (13000, 2.1517128874388254), (23000, 2.3034257748776508), (33000, 2.407830342577488), (43000, 2.4779771615008155), (53000, 2.5513866231647633), (63000, 2.5742251223491026), (73000, 2.579119086460033), (83000, 2.6443719412724302), (93000, 2.6769983686786296), (103000, 2.66394779771615), (113000, 2.701468189233279), (123000, 2.7389885807504077), (133000, 2.7471451876019577), (143000, 2.7438825448613375)]}\n",
    "data_challenge = {'arc_challenge': [(0, 1.0), (1, 1.0), (2, 0.996078431372549), (4, 0.9921568627450981), (8, 0.9372549019607844), (16, 0.8980392156862745), (32, 0.8745098039215686), (64, 0.8392156862745098), (128, 0.8862745098039216), (256, 0.9058823529411765), (512, 0.8392156862745098), (1000, 0.8784313725490197), (3000, 0.8980392156862745), (13000, 1.0509803921568628), (23000, 1.2), (33000, 1.3019607843137255), (43000, 1.2470588235294118), (53000, 1.3490196078431371), (63000, 1.3607843137254902), (73000, 1.3568627450980393), (83000, 1.4509803921568627), (93000, 1.4941176470588236), (103000, 1.5098039215686276), (113000, 1.5490196078431373), (123000, 1.5450980392156863), (133000, 1.5529411764705883), (143000, 1.5254901960784315)]}\n",
    "data_easy = [i[1] for i in data_easy['arc_easy'] if i[0] in steps + [0]]\n",
    "data_challenge = [i[1] for i in data_challenge['arc_challenge'] if i[0] in steps + [0]]\n",
    "print(data_easy)\n",
    "print(data_challenge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dfac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh, axes = plt.subplots(1, 3, figsize=(12, 3.2), sharex=False, sharey=True)\n",
    "\n",
    "ax=axes[0]\n",
    "sns.scatterplot(x=steps,\n",
    "            y=corr_models,\n",
    "            ax=ax);\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('steps')      \n",
    "ax.set_ylabel('brain correlation')\n",
    "r, p = pearsonr(np.log(steps), \n",
    "                corr_models)\n",
    "ax.text(0.05, 0.95,'$r={:.2f}$\\n$p={:.1e}$'.format(r,p),\n",
    "              ha='left', va='top', fontsize=11, transform=ax.transAxes)\n",
    "\n",
    "ax=axes[1]\n",
    "\n",
    "sns.scatterplot(x=data_challenge,\n",
    "            y=corr_models,\n",
    "            ax=ax);\n",
    "ax.set_xlabel('arc_challenge')\n",
    "\n",
    "fh.subplots_adjust(wspace=0.05)\n",
    "\n",
    "ax=axes[2]\n",
    "sns.scatterplot(x=data_easy,\n",
    "            y=corr_models,\n",
    "            ax=ax);\n",
    "ax.set_xlabel('arc_easy')\n",
    "\n",
    "fh.subplots_adjust(wspace=0.05)\n",
    "\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'llms_corr_above3b.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167fffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_models = np.mean(corr_voxels_models[:, :len(corr_voxels_models[0]) // 2], axis=1)\n",
    "right_models = np.mean(corr_voxels_models[:, len(corr_voxels_models[0]) // 2:], axis=1)\n",
    "delta_models = left_models-right_models\n",
    "print(left_models-right_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ab449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh, axes = plt.subplots(1, 3, figsize=(12, 3.2), sharex=False, sharey=True)\n",
    "\n",
    "ax=axes[0]\n",
    "sns.scatterplot(x=steps,\n",
    "            y=left_models,\n",
    "            ax=ax);\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('steps')      \n",
    "ax.set_ylabel('brain correlation')\n",
    "r, p = pearsonr(np.log(steps), \n",
    "                left_models)\n",
    "ax.text(0.05, 0.95,'$r={:.2f}$\\n$p={:.1e}$'.format(r,p),\n",
    "              ha='left', va='top', fontsize=11, transform=ax.transAxes)\n",
    "\n",
    "ax=axes[1]\n",
    "\n",
    "sns.scatterplot(x=data_challenge,\n",
    "            y=left_models,\n",
    "            ax=ax);\n",
    "ax.set_xlabel('arc_challenge')\n",
    "\n",
    "fh.subplots_adjust(wspace=0.05)\n",
    "\n",
    "ax=axes[2]\n",
    "sns.scatterplot(x=data_easy,\n",
    "            y=left_models,\n",
    "            ax=ax);\n",
    "ax.set_xlabel('arc_easy')\n",
    "\n",
    "fh.subplots_adjust(wspace=0.05)\n",
    "\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'llms_corr_above3b.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33a3a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh, axes = plt.subplots(1, 3, figsize=(12, 3.2), sharex=False, sharey=True)\n",
    "\n",
    "ax=axes[0]\n",
    "sns.scatterplot(x=steps,\n",
    "            y=right_models,\n",
    "            ax=ax);\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('steps')      \n",
    "ax.set_ylabel('brain correlation')\n",
    "r, p = pearsonr(np.log(steps), \n",
    "                right_models)\n",
    "ax.text(0.05, 0.95,'$r={:.2f}$\\n$p={:.1e}$'.format(r,p),\n",
    "              ha='left', va='top', fontsize=11, transform=ax.transAxes)\n",
    "\n",
    "ax=axes[1]\n",
    "\n",
    "sns.scatterplot(x=data_challenge,\n",
    "            y=right_models,\n",
    "            ax=ax);\n",
    "ax.set_xlabel('arc_challenge')\n",
    "\n",
    "fh.subplots_adjust(wspace=0.05)\n",
    "\n",
    "ax=axes[2]\n",
    "sns.scatterplot(x=data_easy,\n",
    "            y=right_models,\n",
    "            ax=ax);\n",
    "ax.set_xlabel('arc_easy')\n",
    "\n",
    "fh.subplots_adjust(wspace=0.05)\n",
    "\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'llms_corr_above3b.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8855639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh, axes = plt.subplots(1, 3, figsize=(12, 3.2), sharex=False, sharey=True)\n",
    "\n",
    "ax=axes[0]\n",
    "sns.scatterplot(x=steps,\n",
    "            y=delta_models,\n",
    "            ax=ax);\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('steps')      \n",
    "ax.set_ylabel('brain correlation')\n",
    "r, p = pearsonr(np.log(steps), \n",
    "                delta_models)\n",
    "ax.text(0.05, 0.95,'$r={:.2f}$\\n$p={:.1e}$'.format(r,p),\n",
    "              ha='left', va='top', fontsize=11, transform=ax.transAxes)\n",
    "\n",
    "ax=axes[1]\n",
    "\n",
    "sns.scatterplot(x=data_challenge,\n",
    "            y=delta_models,\n",
    "            ax=ax);\n",
    "ax.set_xlabel('arc_challenge')\n",
    "\n",
    "fh.subplots_adjust(wspace=0.05)\n",
    "\n",
    "ax=axes[2]\n",
    "sns.scatterplot(x=data_easy,\n",
    "            y=delta_models,\n",
    "            ax=ax);\n",
    "ax.set_xlabel('arc_easy')\n",
    "\n",
    "fh.subplots_adjust(wspace=0.05)\n",
    "\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'llms_corr_above3b.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6988441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Exemple de données\n",
    "data = {\n",
    "    'brain_score': corr_models,\n",
    "    'arcevale' : data_easy,\n",
    "    'arcevalc': data_challenge\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "X = df[['arcevale', 'arcevalc']]\n",
    "Y = df['brain_score']\n",
    "\n",
    "# Ajouter une constante pour le terme d'interception\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Faire la régression multiple\n",
    "model = sm.OLS(Y, X).fit()\n",
    "\n",
    "# Afficher les résultats\n",
    "print(model.summary())\n",
    "\n",
    "# Afficher les coefficients avec les noms des variables\n",
    "for variable, coefficient in zip(X.columns, model.params):\n",
    "    print(f\"{variable}: {coefficient}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9376ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh, axes = plt.subplots(1, 3, figsize=(12, 3.2), sharex=False, sharey=True)\n",
    "\n",
    "data = [corr_models[i] for i in range(len(corr_models))]\n",
    "data = np.array(data)\n",
    "data = (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "data_challenge = np.array(data_challenge)\n",
    "data_challenge = (data_challenge - np.min(data_challenge)) / (np.max(data_challenge) - np.min(data_challenge))\n",
    "data_easy = np.array(data_easy)\n",
    "data_easy = (data_easy - np.min(data_easy)) / (np.max(data_easy) - np.min(data_easy))\n",
    "\n",
    "ax=axes[0]\n",
    "sns.scatterplot(x=steps,\n",
    "            y=data,\n",
    "            ax=ax);\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('steps')      \n",
    "ax.set_ylabel('brain correlation')\n",
    "\n",
    "ax=axes[1]\n",
    "\n",
    "sns.scatterplot(x=steps,\n",
    "            y=data_challenge,\n",
    "            ax=ax);\n",
    "ax.set_xlabel('steps')\n",
    "ax.set_ylabel(\"arc easy\")\n",
    "\n",
    "fh.subplots_adjust(wspace=0.05)\n",
    "\n",
    "ax=axes[2]\n",
    "sns.scatterplot(x=steps,\n",
    "            y=data_easy,\n",
    "            ax=ax);\n",
    "ax.set_xlabel('steps')\n",
    "ax.set_ylabel(\"arc challenge\")\n",
    "fh.subplots_adjust(wspace=0.05)\n",
    "\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'llms_corr_above3b.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9931bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh, axes = plt.subplots(1, 3, figsize=(12, 3.2), sharex=False, sharey=True)\n",
    "\n",
    "data = [delta_models[i] / np.log(corr_models[i]) for i in range(len(corr_models))]\n",
    "\n",
    "ax=axes[0]\n",
    "sns.scatterplot(x=steps,\n",
    "            y=data,\n",
    "            ax=ax);\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('steps')      \n",
    "ax.set_ylabel('brain correlation')\n",
    "r, p = pearsonr(np.log(steps), \n",
    "                delta_models)\n",
    "ax.text(0.05, 0.95,'$r={:.2f}$\\n$p={:.1e}$'.format(r,p),\n",
    "              ha='left', va='top', fontsize=11, transform=ax.transAxes)\n",
    "\n",
    "ax=axes[1]\n",
    "\n",
    "sns.scatterplot(x=data_challenge,\n",
    "            y=data,\n",
    "            ax=ax);\n",
    "ax.set_xlabel('arc_challenge')\n",
    "\n",
    "fh.subplots_adjust(wspace=0.05)\n",
    "\n",
    "ax=axes[2]\n",
    "sns.scatterplot(x=data_easy,\n",
    "            y=data,\n",
    "            ax=ax);\n",
    "ax.set_xlabel('arc_easy')\n",
    "\n",
    "print(np.corrcoef(data, data_easy))\n",
    "print(np.corrcoef(data, data_challenge))\n",
    "print(np.corrcoef(data, steps))\n",
    "\n",
    "fh.subplots_adjust(wspace=0.05)\n",
    "\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'llms_corr_above3b.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2738ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ Slopes, voxelwise ################################\n",
    "slopes = []\n",
    "tvalues = []\n",
    "pvalues = []\n",
    "for idx_voxel in range(n_voxels):\n",
    "    y = corr_models\n",
    "    x = data_easy\n",
    "    x = sm.add_constant(x)\n",
    "    lm = sm.OLS(y, x)\n",
    "    res = lm.fit()\n",
    "    slopes.append(res.params[1])\n",
    "    tvalues.append(res.tvalues[1])\n",
    "    pvalues.append(res.pvalues[1])\n",
    "\n",
    "slopes = np.array(slopes)\n",
    "tvalues = np.array(tvalues)\n",
    "pvalues = np.array(pvalues)\n",
    "\n",
    "vtmp = slopes.copy()\n",
    "p_thsld = 10**-3\n",
    "t_thsld = np.abs(scipy.stats.t.ppf(p_thsld/2, df=n_models-2)) #two-sided\n",
    "print(t_thsld)\n",
    "vtmp[np.abs(tvalues) < t_thsld] = np.nan\n",
    "imgtmp = nifti_masker.inverse_transform(vtmp)\n",
    "\n",
    "fh = plt.figure(figsize=(12,3))\n",
    "ax = plt.subplot(111)\n",
    "plotting.plot_glass_brain(imgtmp, threshold=0., display_mode='lyrz', cbar_tick_format='%.3f',\n",
    "                          plot_abs=False, colorbar=True, axes=ax)\n",
    "plotting.show()\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'glassbrain_slopes.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba95c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ Slopes, voxelwise ################################\n",
    "slopes = []\n",
    "tvalues = []\n",
    "pvalues = []\n",
    "for idx_voxel in range(n_voxels):\n",
    "    y = corr_models\n",
    "    x = data_challenge\n",
    "    x = sm.add_constant(x)\n",
    "    lm = sm.OLS(y, x)\n",
    "    res = lm.fit()\n",
    "    slopes.append(res.params[1])\n",
    "    tvalues.append(res.tvalues[1])\n",
    "    pvalues.append(res.pvalues[1])\n",
    "\n",
    "slopes = np.array(slopes)\n",
    "tvalues = np.array(tvalues)\n",
    "pvalues = np.array(pvalues)\n",
    "\n",
    "vtmp = slopes.copy()\n",
    "p_thsld = 10**-3\n",
    "t_thsld = np.abs(scipy.stats.t.ppf(p_thsld/2, df=n_models-2)) #two-sided\n",
    "print(t_thsld)\n",
    "vtmp[np.abs(tvalues) < t_thsld] = np.nan\n",
    "imgtmp = nifti_masker.inverse_transform(vtmp)\n",
    "\n",
    "fh = plt.figure(figsize=(12,3))\n",
    "ax = plt.subplot(111)\n",
    "plotting.plot_glass_brain(imgtmp, threshold=0., display_mode='lyrz', cbar_tick_format='%.3f',\n",
    "                          plot_abs=False, colorbar=True, axes=ax)\n",
    "plotting.show()\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'glassbrain_slopes.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76909c8-0de0-45c5-bc6d-53cdab9bbbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### other x-axis: hellaswag, perplexity ######################\n",
    "\n",
    "fh = plot_xy(ppl_models, corr_models, 'perplexity', 'brain correlation', invert_xaxis=True)\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'llms_ppl_corr.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))\n",
    "    \n",
    "fh = plot_xy(hellaswag_models, corr_models, 'hellaswag', 'brain correlation')\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'llms_hellaswag_corr.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))\n",
    "\n",
    "fh = plot_xy(ppl_models, corr_models_rv, 'perplexity', 'brain correlation', invert_xaxis=True)\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'llms_ppl_corr_rv.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))\n",
    "    \n",
    "fh = plot_xy(hellaswag_models, corr_models_rv, 'hellaswag', 'brain correlation')\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'llms_hellaswag_corr_rv.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee0ea6b-3e0c-4700-828d-c94dd268b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## consider only largest model (10 models out of 28)\n",
    "params_thsld = 3*10**9\n",
    "print((n_parameters>params_thsld).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d62938-67cf-4fc1-9a33-232e3f0a6fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh, axes = plt.subplots(1, 3, figsize=(12, 3.2), sharex=False, sharey=True)\n",
    "\n",
    "ax=axes[0]\n",
    "sns.regplot(x=n_parameters[n_parameters>params_thsld],\n",
    "            y=corr_models[n_parameters>params_thsld],\n",
    "            logx=True, ax=ax);\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('number of parameters')      \n",
    "ax.set_ylabel('brain correlation')\n",
    "r, p = pearsonr(np.log(n_parameters[n_parameters>params_thsld]), \n",
    "                corr_models[n_parameters>params_thsld])\n",
    "ax.text(0.05, 0.95,'$r={:.2f}$\\n$p={:.1e}$'.format(r,p),\n",
    "              ha='left', va='top', fontsize=11, transform=ax.transAxes)\n",
    "\n",
    "ax=axes[1]\n",
    "sns.regplot(x=ppl_models[n_parameters>params_thsld],\n",
    "            y=corr_models[n_parameters>params_thsld],\n",
    "            ax=ax);\n",
    "ax.invert_xaxis()\n",
    "ax.set_xlabel('perplexity')\n",
    "r, p = pearsonr(ppl_models[n_parameters>params_thsld],\n",
    "                corr_models[n_parameters>params_thsld])\n",
    "ax.text(0.05, 0.95,'$r={:.2f}$\\n$p={:.1e}$'.format(r,p),\n",
    "              ha='left', va='top', fontsize=11, transform=ax.transAxes)\n",
    "\n",
    "ax=axes[2]\n",
    "sns.regplot(x=hellaswag_models[n_parameters>params_thsld],\n",
    "            y=corr_models[n_parameters>params_thsld],\n",
    "            ax=ax);\n",
    "ax.set_xlabel('hellaswag')\n",
    "r, p = pearsonr(hellaswag_models[n_parameters>params_thsld],\n",
    "                corr_models[n_parameters>params_thsld])\n",
    "ax.text(0.05, 0.95,'$r={:.2f}$\\n$p={:.1e}$'.format(r,p),\n",
    "              ha='left', va='top', fontsize=11, transform=ax.transAxes)\n",
    "\n",
    "fh.subplots_adjust(wspace=0.05)\n",
    "\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'llms_corr_above3b.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8dfd8d-4290-401d-9fcf-bc37d3a6638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh, axes = plt.subplots(1, 3, figsize=(12, 3.2), sharex=False, sharey=True)\n",
    "ax=axes[0]\n",
    "sns.regplot(x=n_parameters[n_parameters>params_thsld],\n",
    "            y=corr_models_rv[n_parameters>params_thsld],\n",
    "            logx=True, ax=ax);\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('number of parameters')      \n",
    "ax.set_ylabel('brain correlation')\n",
    "r, p = pearsonr(np.log(n_parameters[n_parameters>params_thsld]), \n",
    "                corr_models_rv[n_parameters>params_thsld])\n",
    "ax.text(0.05, 0.95,'$r={:.2f}$\\n$p={:.1e}$'.format(r,p),\n",
    "              ha='left', va='top', fontsize=11, transform=ax.transAxes)\n",
    "\n",
    "ax=axes[1]\n",
    "sns.regplot(x=ppl_models[n_parameters>params_thsld],\n",
    "            y=corr_models_rv[n_parameters>params_thsld],\n",
    "            ax=ax);\n",
    "ax.invert_xaxis()\n",
    "ax.set_xlabel('perplexity')    \n",
    "r, p = pearsonr(ppl_models[n_parameters>params_thsld],\n",
    "                corr_models_rv[n_parameters>params_thsld])\n",
    "ax.text(0.05, 0.95,'$r={:.2f}$\\n$p={:.1e}$'.format(r,p),\n",
    "              ha='left', va='top', fontsize=11, transform=ax.transAxes)  \n",
    "\n",
    "ax=axes[2]\n",
    "sns.regplot(x=hellaswag_models[n_parameters>params_thsld],\n",
    "            y=corr_models_rv[n_parameters>params_thsld],\n",
    "            ax=ax);\n",
    "ax.set_xlabel('hellaswag') \n",
    "r, p = pearsonr(hellaswag_models[n_parameters>params_thsld],\n",
    "                corr_models_rv[n_parameters>params_thsld])\n",
    "ax.text(0.05, 0.95,'$r={:.2f}$\\n$p={:.1e}$'.format(r,p),\n",
    "              ha='left', va='top', fontsize=11, transform=ax.transAxes)\n",
    "\n",
    "fh.subplots_adjust(wspace=0.05)\n",
    "\n",
    "if save_fig:\n",
    "    fh.savefig(os.path.join(fig_folder, 'llms_corr_above3b_rv.pdf'), bbox_inches='tight', facecolor=(1,1,1,0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
